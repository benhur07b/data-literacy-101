<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="description" content="There are three basic design principles that you must be aware of when communicating visually with data—**simplification, heirarchy, and layout**.">
<meta name="keywords" content="design,principles">
<link rel="icon" href="../../favicon.ico">
<title>Design Principles | BNHR - Data Literacy 101</title>
<link rel="stylesheet" href="https://unpkg.com/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">
<link rel="stylesheet" href="https://unpkg.com/bootstrap@4.6.0/dist/css/bootstrap.min.css">
<link rel="stylesheet" href="https://unpkg.com/prismjs@1.23.0/themes/prism.css">
<style>

/* Base */

html {
  font-family: sans-serif;
  line-height: 1.15;
  -webkit-text-size-adjust: 100%;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}

body {
  margin: 0;
  font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", "Liberation Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
  font-size: 16px;
  font-weight: 400;
  line-height: 1.5;
  color: #222;
  text-align: left;
  background-color: #fff;
}

*,
::after,
::before {
	box-sizing: border-box;
}

ul,
ol {
	margin-top: 0;
	margin-bottom: 1rem;
}

a {
	color: #007bff;
	text-decoration: none;
	background-color: transparent;
}

a:hover {
	color: #0056b3;
	text-decoration: underline;
}

hr {
  box-sizing: content-box;
  height: 0;
  overflow: visible;
}

p {
  margin-top: 0;
  margin-bottom: 1rem;
}

/* Main */

#livemark-main {
  padding: 24px 20px;
  min-height: 100vh;
}

#livemark-main h1 {
  margin-top: 4px !important;
  padding-bottom: 12px !important;
}

#livemark-main h1 a.heading,
#livemark-main h2 a.heading,
#livemark-main h3 a.heading,
#livemark-main h4 a.heading,
#livemark-main h5 a.heading,
#livemark-main h6 a.heading {
  display: none;
}

#livemark-main h2:hover a.heading,
#livemark-main h3:hover a.heading,
#livemark-main h4:hover a.heading,
#livemark-main h5:hover a.heading,
#livemark-main h6:hover a.heading {
  display: inline;
  margin-left: 8px;
  color: #aaa;
  font-weight: normal;
  text-decoration: none;
}

#livemark-main h2 a.heading:hover,
#livemark-main h3 a.heading:hover,
#livemark-main h4 a.heading:hover,
#livemark-main h5 a.heading:hover,
#livemark-main h6 a.heading:hover {
  text-decoration: underline;
}

@media only screen and (min-width: 768px) {
  #livemark-main {
    margin-left: 300px;
    border-left: dashed 1px #ccc;
  }
}

@media only screen and (min-width: 992px) {
  #livemark-main {
    margin-right: 300px;
    border-right: dashed 1px #ccc;
  }
}

#livemark-main .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

#livemark-main .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

#livemark-main .anchor:focus {
  outline: none;
}

#livemark-main h1 .octicon-link,
#livemark-main h2 .octicon-link,
#livemark-main h3 .octicon-link,
#livemark-main h4 .octicon-link,
#livemark-main h5 .octicon-link,
#livemark-main h6 .octicon-link {
  color: #1b1f23;
  vertical-align: middle;
  visibility: hidden;
}

#livemark-main h1:hover .anchor,
#livemark-main h2:hover .anchor,
#livemark-main h3:hover .anchor,
#livemark-main h4:hover .anchor,
#livemark-main h5:hover .anchor,
#livemark-main h6:hover .anchor {
  text-decoration: none;
}

#livemark-main h1:hover .anchor .octicon-link,
#livemark-main h2:hover .anchor .octicon-link,
#livemark-main h3:hover .anchor .octicon-link,
#livemark-main h4:hover .anchor .octicon-link,
#livemark-main h5:hover .anchor .octicon-link,
#livemark-main h6:hover .anchor .octicon-link {
  visibility: visible;
}

#livemark-main h1:hover .anchor .octicon-link:before,
#livemark-main h2:hover .anchor .octicon-link:before,
#livemark-main h3:hover .anchor .octicon-link:before,
#livemark-main h4:hover .anchor .octicon-link:before,
#livemark-main h5:hover .anchor .octicon-link:before,
#livemark-main h6:hover .anchor .octicon-link:before {
  width: 16px;
  height: 16px;
  content: ' ';
  display: inline-block;
  background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16' version='1.1' width='16' height='16' aria-hidden='true'%3E%3Cpath fill-rule='evenodd' d='M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z'%3E%3C/path%3E%3C/svg%3E");
}

#livemark-main {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  line-height: 1.5;
  color: #222;
  font-family: system-ui, -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;
  line-height: 1.5;
  word-wrap: break-word;
}

#livemark-main details {
  display: block;
}

#livemark-main summary {
  display: list-item;
}

#livemark-main a {
  background-color: initial;
}

#livemark-main a:active,
#livemark-main a:hover {
  outline-width: 0;
}

#livemark-main strong {
  font-weight: inherit;
  font-weight: bolder;
}

#livemark-main h1 {
  font-size: 2em;
  margin: .67em 0;
}

#livemark-main img {
  border-style: none;
}

#livemark-main code,
#livemark-main kbd,
#livemark-main pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

#livemark-main hr {
  box-sizing: initial;
  height: 0;
  overflow: visible;
}

#livemark-main input {
  font: inherit;
  margin: 0;
}

#livemark-main input {
  overflow: visible;
}

#livemark-main [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

#livemark-main * {
  box-sizing: border-box;
}

#livemark-main input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

#livemark-main a {
  color: #0366d6;
  text-decoration: none;
}

#livemark-main a:hover {
  text-decoration: underline;
}

#livemark-main strong {
  font-weight: 600;
}

#livemark-main hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #dfe2e5;
}

#livemark-main hr:after,
#livemark-main hr:before {
  display: table;
  content: "";
}

#livemark-main hr:after {
  clear: both;
}

/* NOTE: is it possible to find a better fix for not breaking TablePlugin's styles? */
#livemark-main table:not(.dataTable) {
  border-spacing: 0;
  border-collapse: collapse;
}

#livemark-main td,
#livemark-main th {
  padding: 0;
}

#livemark-main details summary {
  cursor: pointer;
}

#livemark-main kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 11px SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  line-height: 10px;
  color: #444d56;
  vertical-align: middle;
  background-color: #fafbfc;
  border: 1px solid #d1d5da;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #d1d5da;
}

#livemark-main h1,
#livemark-main h2,
#livemark-main h3,
#livemark-main h4,
#livemark-main h5,
#livemark-main h6 {
  margin-top: 0;
  margin-bottom: 0;
}

#livemark-main h1 {
  font-size: 32px;
}

#livemark-main h1,
#livemark-main h2 {
  font-weight: 600;
}

#livemark-main h2 {
  font-size: 24px;
}

#livemark-main h3 {
  font-size: 20px;
}

#livemark-main h3,
#livemark-main h4 {
  font-weight: 600;
}

#livemark-main h4 {
  font-size: 16px;
}

#livemark-main h5 {
  font-size: 14px;
}

#livemark-main h5,
#livemark-main h6 {
  font-weight: 600;
}

#livemark-main h6 {
  font-size: 12px;
}

#livemark-main p {
  margin-top: 0;
  margin-bottom: 10px;
}

#livemark-main blockquote {
  margin: 0;
}

#livemark-main ol,
#livemark-main ul {
  padding-left: 0;
  margin-top: 0;
  margin-bottom: 0;
}

#livemark-main ol ol,
#livemark-main ul ol {
  list-style-type: lower-roman;
}

#livemark-main ol ol ol,
#livemark-main ol ul ol,
#livemark-main ul ol ol,
#livemark-main ul ul ol {
  list-style-type: lower-alpha;
}

#livemark-main dd {
  margin-left: 0;
}

#livemark-main code,
#livemark-main pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 12px;
}

#livemark-main pre {
  margin-top: 0;
  margin-bottom: 0;
}

#livemark-main input::-webkit-inner-spin-button,
#livemark-main input::-webkit-outer-spin-button {
  margin: 0;
  -webkit-appearance: none;
  appearance: none;
}

#livemark-main :checked+.radio-label {
  position: relative;
  z-index: 1;
  border-color: #0366d6;
}

#livemark-main .border {
  border: 1px solid #e1e4e8!important;
}

#livemark-main .border-0 {
  border: 0!important;
}

#livemark-main .border-bottom {
  border-bottom: 1px solid #e1e4e8!important;
}

#livemark-main .rounded-1 {
  border-radius: 3px!important;
}

#livemark-main .bg-white {
  background-color: #fff!important;
}

#livemark-main .bg-gray-light {
  background-color: #fafbfc!important;
}

#livemark-main .text-gray-light {
  color: #666!important;
}

#livemark-main .mb-0 {
  margin-bottom: 0!important;
}

#livemark-main .my-2 {
  margin-top: 8px!important;
  margin-bottom: 8px!important;
}

#livemark-main .pl-0 {
  padding-left: 0!important;
}

#livemark-main .py-0 {
  padding-top: 0!important;
  padding-bottom: 0!important;
}

#livemark-main .pl-1 {
  padding-left: 4px!important;
}

#livemark-main .pl-2 {
  padding-left: 8px!important;
}

#livemark-main .py-2 {
  padding-top: 8px!important;
  padding-bottom: 8px!important;
}

#livemark-main .pl-3,
#livemark-main .px-3 {
  padding-left: 16px!important;
}

#livemark-main .px-3 {
  padding-right: 16px!important;
}

#livemark-main .pl-4 {
  padding-left: 24px!important;
}

#livemark-main .pl-5 {
  padding-left: 32px!important;
}

#livemark-main .pl-6 {
  padding-left: 40px!important;
}

#livemark-main .f6 {
  font-size: 12px!important;
}

#livemark-main .lh-condensed {
  line-height: 1.25!important;
}

#livemark-main .text-bold {
  font-weight: 600!important;
}

#livemark-main .pl-c {
  color: #666;
}

#livemark-main .pl-c1,
#livemark-main .pl-s .pl-v {
  color: #005cc5;
}

#livemark-main .pl-e,
#livemark-main .pl-en {
  color: #6f42c1;
}

#livemark-main .pl-s .pl-s1,
#livemark-main .pl-smi {
  color: #222;
}

#livemark-main .pl-ent {
  color: #22863a;
}

#livemark-main .pl-k {
  color: #d73a49;
}

#livemark-main .pl-pds,
#livemark-main .pl-s,
#livemark-main .pl-s .pl-pse .pl-s1,
#livemark-main .pl-sr,
#livemark-main .pl-sr .pl-cce,
#livemark-main .pl-sr .pl-sra,
#livemark-main .pl-sr .pl-sre {
  color: #032f62;
}

#livemark-main .pl-smw,
#livemark-main .pl-v {
  color: #e36209;
}

#livemark-main .pl-bu {
  color: #b31d28;
}

#livemark-main .pl-ii {
  color: #fafbfc;
  background-color: #b31d28;
}

#livemark-main .pl-c2 {
  color: #fafbfc;
  background-color: #d73a49;
}

#livemark-main .pl-c2:before {
  content: "^M";
}

#livemark-main .pl-sr .pl-cce {
  font-weight: 700;
  color: #22863a;
}

#livemark-main .pl-ml {
  color: #735c0f;
}

#livemark-main .pl-mh,
#livemark-main .pl-mh .pl-en,
#livemark-main .pl-ms {
  font-weight: 700;
  color: #005cc5;
}

#livemark-main .pl-mi {
  font-style: italic;
  color: #222;
}

#livemark-main .pl-mb {
  font-weight: 700;
  color: #222;
}

#livemark-main .pl-md {
  color: #b31d28;
  background-color: #ffeef0;
}

#livemark-main .pl-mi1 {
  color: #22863a;
  background-color: #f0fff4;
}

#livemark-main .pl-mc {
  color: #e36209;
  background-color: #ffebda;
}

#livemark-main .pl-mi2 {
  color: #f6f8fa;
  background-color: #005cc5;
}

#livemark-main .pl-mdr {
  font-weight: 700;
  color: #6f42c1;
}

#livemark-main .pl-ba {
  color: #586069;
}

#livemark-main .pl-sg {
  color: #959da5;
}

#livemark-main .pl-corl {
  text-decoration: underline;
  color: #032f62;
}

#livemark-main .mb-0 {
  margin-bottom: 0!important;
}

#livemark-main .my-2 {
  margin-bottom: 8px!important;
}

#livemark-main .my-2 {
  margin-top: 8px!important;
}

#livemark-main .pl-0 {
  padding-left: 0!important;
}

#livemark-main .py-0 {
  padding-top: 0!important;
  padding-bottom: 0!important;
}

#livemark-main .pl-1 {
  padding-left: 4px!important;
}

#livemark-main .pl-2 {
  padding-left: 8px!important;
}

#livemark-main .py-2 {
  padding-top: 8px!important;
  padding-bottom: 8px!important;
}

#livemark-main .pl-3 {
  padding-left: 16px!important;
}

#livemark-main .pl-4 {
  padding-left: 24px!important;
}

#livemark-main .pl-5 {
  padding-left: 32px!important;
}

#livemark-main .pl-6 {
  padding-left: 40px!important;
}

#livemark-main .pl-7 {
  padding-left: 48px!important;
}

#livemark-main .pl-8 {
  padding-left: 64px!important;
}

#livemark-main .pl-9 {
  padding-left: 80px!important;
}

#livemark-main .pl-10 {
  padding-left: 96px!important;
}

#livemark-main .pl-11 {
  padding-left: 112px!important;
}

#livemark-main .pl-12 {
  padding-left: 128px!important;
}

#livemark-main hr {
  border-bottom-color: #eee;
}

#livemark-main kbd {
  display: inline-block;
  padding: 3px 5px;
  font: 11px SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  line-height: 10px;
  color: #444d56;
  vertical-align: middle;
  background-color: #fafbfc;
  border: 1px solid #d1d5da;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #d1d5da;
}

#livemark-main:after,
#livemark-main:before {
  display: table;
  content: "";
}

#livemark-main:after {
  clear: both;
}

#livemark-main a:not([href]) {
  color: inherit;
  text-decoration: none;
}

#livemark-main blockquote,
#livemark-main details,
#livemark-main dl,
#livemark-main ol,
#livemark-main p,
#livemark-main pre,
#livemark-main table:not(.dataTable),
#livemark-main ul {
  margin-top: 0;
  margin-bottom: 16px;
}

#livemark-main hr {
  height: .25em;
  padding: 0;
  margin: 24px 0;
  background-color: #e1e4e8;
  border: 0;
}

#livemark-main blockquote {
  padding: 0 1em;
  color: #666;
  border-left: .25em solid #dfe2e5;
}

#livemark-main blockquote>:first-child {
  margin-top: 0;
}

#livemark-main blockquote>:last-child {
  margin-bottom: 0;
}

#livemark-main h1,
#livemark-main h2,
#livemark-main h3,
#livemark-main h4,
#livemark-main h5,
#livemark-main h6 {
  margin-top: 24px;
  margin-bottom: 16px;
  font-weight: 600;
  line-height: 1.25;
}

#livemark-main h1 {
  font-size: 2em;
}

#livemark-main h1,
#livemark-main h2 {
  padding-bottom: .3em;
  border-bottom: 1px solid #eaecef;
}

#livemark-main h2 {
  font-size: 1.5em;
}

#livemark-main h3 {
  font-size: 1.25em;
}

#livemark-main h4 {
  font-size: 1em;
}

#livemark-main h5 {
  font-size: .875em;
}

#livemark-main h6 {
  font-size: .85em;
  color: #666;
}

#livemark-main ol,
#livemark-main ul {
  padding-left: 2em;
}

#livemark-main ol ol,
#livemark-main ol ul,
#livemark-main ul ol,
#livemark-main ul ul {
  margin-top: 0;
  margin-bottom: 0;
}

#livemark-main li {
  word-wrap: break-all;
}

#livemark-main li>p {
  margin-top: 16px;
}

#livemark-main li+li {
  margin-top: .25em;
}

#livemark-main dl {
  padding: 0;
}

#livemark-main dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
}

#livemark-main dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

#livemark-main table:not(.dataTable) {
  display: block;
  width: 100%;
  overflow: auto;
}

#livemark-main table:not(.dataTable) th {
  font-weight: 600;
}

#livemark-main table:not(.dataTable) td,
#livemark-main table:not(.dataTable) th {
  padding: 6px 13px;
  border: 1px solid #dfe2e5;
}

#livemark-main table:not(.dataTable) tr {
  background-color: #fff;
  border-top: 1px solid #c6cbd1;
}

#livemark-main table:not(.dataTable) tr:nth-child(2n) {
  background-color: #f6f8fa;
}

#livemark-main img {
  max-width: 100%;
  box-sizing: initial;
  background-color: #fff;
}

#livemark-main img[align=right] {
  padding-left: 20px;
}

#livemark-main img[align=left] {
  padding-right: 20px;
}

#livemark-main code {
  padding: .2em .4em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(27,31,35,.05);
  border-radius: 3px;
}

#livemark-main pre {
  word-wrap: normal;
}

#livemark-main pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

#livemark-main .highlight {
  margin-bottom: 16px;
}

#livemark-main .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

#livemark-main .highlight pre,
#livemark-main pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f6f8fa;
  border-radius: 3px;
}

#livemark-main pre code {
  display: inline;
  max-width: auto;
  padding: 0;
  margin: 0;
  overflow: visible;
  line-height: inherit;
  word-wrap: normal;
  background-color: initial;
  border: 0;
}

#livemark-main .commit-tease-sha {
  display: inline-block;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 90%;
  color: #444d56;
}

#livemark-main .full-commit .btn-outline:not(:disabled):hover {
  color: #005cc5;
  border-color: #005cc5;
}

#livemark-main .blob-wrapper {
  overflow-x: auto;
  overflow-y: hidden;
}

#livemark-main .blob-wrapper-embedded {
  max-height: 240px;
  overflow-y: auto;
}

#livemark-main .blob-num {
  width: 1%;
  min-width: 50px;
  padding-right: 10px;
  padding-left: 10px;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 12px;
  line-height: 20px;
  color: rgba(27,31,35,.3);
  text-align: right;
  white-space: nowrap;
  vertical-align: top;
  cursor: pointer;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

#livemark-main .blob-num:hover {
  color: rgba(27,31,35,.6);
}

#livemark-main .blob-num:before {
  content: attr(data-line-number);
}

#livemark-main .blob-code {
  position: relative;
  padding-right: 10px;
  padding-left: 10px;
  line-height: 20px;
  vertical-align: top;
}

#livemark-main .blob-code-inner {
  overflow: visible;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,monospace;
  font-size: 12px;
  color: #222;
  word-wrap: normal;
  white-space: pre;
}

#livemark-main .pl-token.active,
#livemark-main .pl-token:hover {
  cursor: pointer;
  background: #ffea7f;
}

#livemark-main .tab-size[data-tab-size="1"] {
  -moz-tab-size: 1;
  tab-size: 1;
}

#livemark-main .tab-size[data-tab-size="2"] {
  -moz-tab-size: 2;
  tab-size: 2;
}

#livemark-main .tab-size[data-tab-size="3"] {
  -moz-tab-size: 3;
  tab-size: 3;
}

#livemark-main .tab-size[data-tab-size="4"] {
  -moz-tab-size: 4;
  tab-size: 4;
}

#livemark-main .tab-size[data-tab-size="5"] {
  -moz-tab-size: 5;
  tab-size: 5;
}

#livemark-main .tab-size[data-tab-size="6"] {
  -moz-tab-size: 6;
  tab-size: 6;
}

#livemark-main .tab-size[data-tab-size="7"] {
  -moz-tab-size: 7;
  tab-size: 7;
}

#livemark-main .tab-size[data-tab-size="8"] {
  -moz-tab-size: 8;
  tab-size: 8;
}

#livemark-main .tab-size[data-tab-size="9"] {
  -moz-tab-size: 9;
  tab-size: 9;
}

#livemark-main .tab-size[data-tab-size="10"] {
  -moz-tab-size: 10;
  tab-size: 10;
}

#livemark-main .tab-size[data-tab-size="11"] {
  -moz-tab-size: 11;
  tab-size: 11;
}

#livemark-main .tab-size[data-tab-size="12"] {
  -moz-tab-size: 12;
  tab-size: 12;
}

#livemark-main .task-list-item {
  list-style-type: none;
}

#livemark-main .task-list-item+.task-list-item {
  margin-top: 3px;
}

#livemark-main .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

/* Left */

#livemark-left {
  visibility: hidden;
  position: fixed;
  width: 300px;
  padding: 10px 40px;
  padding-bottom: 100px;
  left: 0px;
  top: 25px;
  font-size: 125%;
  height: 100vh;
  overflow-y: auto;
  scrollbar-width: none;  /* Firefox */
  -ms-overflow-style: none;  /* Internet Explorer 10+ */
}

/* NOTE: we need to move it to DisplayPlugin (currently unsetting doesn't work) */
body:not(.with-readability) #livemark-left::-webkit-scrollbar {
  display: none; /* Chrome; Safari */
}

#livemark-left > div:not(:last-child) {
  border-bottom: 1px solid #eaecef;
  padding-bottom: 15px;
  margin-bottom: 15px;
}

@media only screen and (min-width: 768px) {
  #livemark-left {
    visibility: visible;
  }
}

/* Right */

#livemark-right {
  visibility: hidden;
  position: fixed;
  width: 300px;
  padding: 10px 40px;
  padding-bottom: 100px;
  right: 0px;
  top: 25px;
  font-size: 125%;
  height: 100vh;
  overflow-y: auto;
  scrollbar-width: none;  /* Firefox */
  -ms-overflow-style: none;  /* Internet Explorer 10+ */
}

/* NOTE: we need to move it to DisplayPlugin (currently unsetting doesn't work) */
body:not(.with-readability) #livemark-right::-webkit-scrollbar {
  display: none; /* Chrome; Safari */
}

#livemark-right > div:not(:last-child) {
  border-bottom: 1px solid #eaecef;
  padding-bottom: 15px;
  margin-bottom: 15px;
}

@media only screen and (min-width: 992px) {
  #livemark-right {
    visibility: visible;
  }
}

</style>
<style>

/* OpenSans Font */
@import url('https://fonts.googleapis.com/css2?family=Open+Sans:wght@400&display=swap');

/* Montserrat Font */
@import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');

body{
    font-family: 'Open Sans', Arial, Helvetica, sans-serif;
    font-size: large;
}

h1, h2, h3, h4, h5, h6 {
    font-family: 'Montserrat', Arial, Helvetica, sans-serif;
    color: #1E1E1E !important;
}

h1 {
    font-weight: 700 !important;
}

h2 {
    font-weight: 600 !important;
}

h3, h4, h5, h6 {
    font-weight: 400 !important;
}

#livemark-left {
    padding-left: 30px;
    padding-right: 20px;
}

#livemark-right {
    padding-left: 20px;
    padding-right: 30px;
}

#livemark-brand {
    font-family: 'Montserrat', Arial, Helvetica, sans-serif;
    color: #1E1E1E !important;
    font-weight: 700 !important;
    font-size: larger;
}

#livemark-brand a:hover {
    color: #1E1E1E !important;
}

#livemark-pages {
    font-family: 'Montserrat', Arial, Helvetica, sans-serif;
}

#livemark-pages a {
    font-weight: 600 !important;
    font-size: smaller;
}

#livemark-pages a:hover {
    color: #1E1E1E !important;
}

#livemark-pages li.active > a {    
    color: #1E1E1E !important;
}

#livemark-pages li.group a.primary::after {
    top: 6px !important;
}

#livemark-topics {
    font-family: 'Montserrat', Arial, Helvetica, sans-serif;
}

#livemark-topics a {
    font-weight: 500 !important;
    font-size: smaller;
}

#livemark-topics a:hover {
    color: #1E1E1E !important;
}

</style>
<style>

#livemark-brand {
  color: #888;
}

#livemark-brand ul {
  overflow: hidden;
  position: relative;
  padding-left: 0;
  margin: 0;
}

#livemark-brand li {
  list-style: none;
}

#livemark-brand a {
  display: inline-block;
  color: currentColor;
  position: relative;
  width: 100%;
  line-height: 100%;
  padding-top: 5px;
  padding-bottom: 5px;
}

#livemark-brand a.active {
  font-weight: 700;
}

#livemark-brand a:hover {
  color: #80b2e6;
}

</style>
<style>

#livemark-pages {
  color: #888;
}

#livemark-pages ul {
  overflow: hidden;
  position: relative;
  padding-left: 0;
  margin: 0;
}

#livemark-pages ul.secondary {
  margin-left: 20px;
  display: none;
}

#livemark-pages li.active ul.secondary {
  display: block;
}

#livemark-pages li {
  list-style: none;
}

#livemark-pages a {
  display: inline-block;
  color: currentColor;
  position: relative;
  width: 100%;
  line-height: 100%;
  padding-top: 5px;
  padding-bottom: 5px;
}

#livemark-pages li.active > a {
  font-weight: 700;
}

#livemark-pages li.group.active > a {
  font-weight: normal;
}

#livemark-pages li.group a.primary::after {
  content: "\f054";
  font-size: 16px;
  font-family: "Font Awesome 5 Free";
  font-weight: 900;
  position: absolute;
  top: 2px;
  right: 0px;
}

#livemark-pages li.group.active a.primary::after {
  content: "\f078";
}

#livemark-pages a:hover {
  color: #80b2e6;
}

</style>
<style>

.livemark-reference {
  display: block;
  /* font-family: ui-monospace, Menlo, Monaco, "Cascadia Mono", "Segoe UI Mono", "Roboto Mono", "Oxygen Mono", "Ubuntu Monospace", "Source Code Pro", "Fira Mono", "Droid Sans Mono", "Courier New", monospace;; */
}

</style>
<style>

#livemark-topics {
  color: #888;
}

#livemark-topics .toc>.toc-list {
  overflow: hidden;
  position: relative;
}

#livemark-topics .toc>.toc-list li {
  list-style: none;
}

#livemark-topics .toc-list {
  padding-left: 0;
  margin: 0;
}

#livemark-topics a.toc-link {
  color: currentColor;
}

#livemark-topics a.toc-link:hover {
  color: #80b2e6;
}

#livemark-topics .is-active-link {
  font-weight: 700;
}

#livemark-topics ul.secondary {
  margin-left: 20px;
  display: none;
}

#livemark-topics li.is-active-li ul.secondary {
  display: block;
}

#livemark-topics li.group a.primary::after {
  content: "\f054";
  font-size: 16px;
  font-family: "Font Awesome 5 Free";
  font-weight: 900;
  position: absolute;
  top: 2px;
  right: 0px;
}

#livemark-topics li.group.is-active-li a.primary::after {
  content: "\f078";
}

#livemark-topics a {
  display: inline-block;
  color: currentColor;
  position: relative;
  width: 100%;
  line-height: 100%;
  padding-top: 5px;
  padding-bottom: 5px;
}

#livemark-topics a:hover {
  color: #80b2e6;
}

</style>
<style>

#livemark-notes {
  color: #aaa;
  text-align: right;
  font-size: 14px;
  float: right;
  visibility: hidden;
}

@media (min-width: 768px) {
  #livemark-notes {
    visibility: visible;
  }
}

#livemark-notes a {
  color: inherit;
}

#livemark-notes a:hover {
  color: #80b2e6;
}

#livemark-notes a[target="_blank"]:after {
  content: "\f35d";
  font-family: "Font Awesome 5 Free";
  font-weight: 900;
  vertical-align: text-top;
  text-decoration: none;
  display: inline-block;
  color: #ccc;
  font-size: 10px;
  margin-left: -1px;
}

#livemark-notes a[target="_blank"]:hover:after {
  color: #80b2e6;
}

</style>
<style>

#livemark-signs {
  color: #888;
  border-top: 1px solid #eaecef;
  margin-top: 24px;
  padding-top: 20px;
  height: 50px;
}

#livemark-signs .next {
  float: right;
}

#livemark-signs a {
  font-size: 20px;
  color: currentColor;
}

#livemark-signs a:hover {
  color: #80b2e6;
}

</style>
<style>

#livemark-rating {
  height: 46px;
}

#livemark-rating iframe {
  margin-top: -5px;
  border: none;
  opacity: 0.5;
}

</style>
<style>

#livemark-about {
  color: #888;
}

</style>
<style>

#livemark-links {
  color: #888;
}

#livemark-links ul {
  overflow: hidden;
  position: relative;
  padding-left: 0;
  margin: 0;
}

#livemark-links li {
  list-style: none;
}

#livemark-links a {
  display: inline-block;
  color: currentColor;
  position: relative;
  width: 100%;
  line-height: 100%;
  padding-top: 5px;
  padding-bottom: 5px;
}

#livemark-links a:hover {
  color: #80b2e6;
}

#livemark-links a[target="_blank"]:after {
  content: "\f35d";
  font-family: "Font Awesome 5 Free";
  font-weight: 900;
  vertical-align: text-top;
  text-decoration: none;
  display: inline-block;
  color: #aaa;
  font-size: 12px;
  margin-left: -2px;
}

#livemark-links a[target="_blank"]:hover:after {
  color: #80b2e6;
}

</style>
<style>

.livemark-audio {
  padding-bottom: 10px;
}

</style>
<style>

.livemark-blog-item {
  margin-bottom: 16px;
  text-align: justify;
}

.livemark-blog-item h2 a:not(.heading) {
  color: #222 !important;
}

</style>
<style>

#livemark-cards .modal-lg {
    max-width: 1000px;
}

</style>
<style>

#livemark-display {
  display: flex;
  position: fixed;
  visibility: hidden;
  justify-content: space-between;
  font-size: 16px;
  color: #888;
  width: 240px;
  bottom: 20px;
  right: 30px;
}

@media only screen and (min-width: 992px) {
  #livemark-display {
    visibility: visible;
  }
}

#livemark-display .control {
  cursor: pointer;
  background-color:#fff;
  box-shadow: 0px 7px 10px #eee;
  border-radius: 50%;
  border: solid 1px #ddd;
  z-index: 100;
}

#livemark-display .control .fa {
  display: inline-block !important;
  opacity: 1 !important;
  padding: 15px;
}

.with-readability {
  font-size: 20px;
}

.with-readability #livemark-main {
  color: #000;
}

.with-readability #livemark-left > *,
.with-readability #livemark-right > * {
  color: #444;
}

.with-readability #livemark-left,
.with-readability #livemark-right {
  scrollbar-width: unset;  /* Firefox */
  -ms-overflow-style: unset;  /* Internet Explorer 10+ */
}

/* NOTE: */
/* temporarily implemented in HtmlPlugin */
/* .with-readability #livemark-left::-webkit-scrollbar, */
/* .with-readability #livemark-right::-webkit-scrollbar { */
  /* display: unset !important; [> Chrome; Safari <] */
/* } */

</style>
<style>

.livemark-image {
  padding-bottom: 10px;
}

</style>
<style>

.livemark-infinity {
  display: none;
}

</style>
<style>

#livemark-mobile {
  position: absolute;
  visibility: hidden;
  z-index: 10000;
  /* NOTE: We can't use "right" because of Mobile Chrome and #34 */
  left: calc(100vw - 60px);
  top: 24px;
}

#livemark-mobile .stack {
  margin-top: 15px;
  display: block;
  cursor: pointer;
}

#livemark-mobile .bar {
  display: block;
  width: 25px;
  height: 3px;
  margin: 5px auto;
  -webkit-transition: all 0.3s ease-in-out;
  transition: all 0.3s ease-in-out;
  background-color: #aaa;
}

@media only screen and (max-width: 768px) {
  #livemark-mobile {
    visibility: visible;
  }

  #livemark-mobile.active {
    position: fixed;
  }

  #livemark-mobile.active .bar:nth-child(2) {
    opacity: 0;
  }

  #livemark-mobile.active .bar:nth-child(1) {
    transform: translateY(8px) rotate(45deg);
  }

  #livemark-mobile.active .bar:nth-child(3) {
    transform: translateY(-8px) rotate(-45deg);
  }

  #livemark-left {
      position: fixed;
      top: 0;
      left: -100vw;
      padding-top: 35px;
      background-color: #fff;
      width: 100vw;
      border-radius: 10px;
      text-align: center;
      transition: 0.3s;
      box-shadow: 0 10px 27px rgba(0, 0, 0, 0.05);
      visibility: visible;
      z-index: 1000;
  }

  #livemark-left.active {
    left: 0;
  }
}

</style>
<link rel="stylesheet" href="https://unpkg.com/paginationjs@2.1.5/dist/pagination.css">
<style>

.livemark-pagination {
  display: none;
}

</style>
<style>

.livemark-remark {
  display: block;
}

</style>
<style>

#livemark-search {
  position: fixed;
  left: 30px;
  width: 240px;
  bottom: 20px;
  z-index:100;
  visibility: hidden;
}

@media only screen and (min-width: 992px) {
  #livemark-search {
    visibility: visible;
  }
}

#livemark-search-input {
  width: 100%;
  outline: none;
  font-size: 20px;
  padding: 7px 10px;
  border-radius: 20px;
  border: solid 1px #ddd;
  box-shadow: 0px 7px 10px #eee;
  color: #888;
}

#livemark-search-input::placeholder {
  color: #888;
}

#livemark-search-input::-webkit-search-decoration,
#livemark-search-input::-webkit-search-cancel-button,
#livemark-search-input::-webkit-search-results-button,
#livemark-search-input::-webkit-search-results-decoration {
  -webkit-appearance:none;
}

#livemark-search-output {
  visibility: hidden;
  width: 100%;
  font-size: 16px;
  padding: 10px 10px;
  border-radius: 20px;
  border: solid 1px #ddd;
  box-shadow: 0px 7px 10px #eee;
  background: white;
  margin-bottom: 10px;
}

#livemark-search-output ul {
  margin: 0;
  padding: 0;
  list-style-type: none;
}

#livemark-search-output li.active {
  font-size: 20px;
  font-weight: bold;
}

#livemark-search-output a {
  color: #5CC820;
  text-decoration: underline;
}

.livemark-search-found {
  background-color: #5CC820;
  color: white;
  font-weight: bold;
  padding: 5px;
  border-radius: 5px;
}

</style>
<style>

.livemark-task pre:first-child {
  margin-bottom: 0 !important;
  border-bottom: dashed 1px #ccc;
}

</style>
<style>

.livemark-video {
  padding-bottom: 10px;
}

</style>
</head>
<body>
<div id="livemark-left">

<div id="livemark-brand">
  <ul>
    <li>
      <a class="active" href="../..">
        BNHR - Data Literacy 101
      </a>
    </li>
  </ul>
</div>

<div id="livemark-pages">
  <ul class="primary">
        <li class="primary  ">
      <a href="../../index.html" class="primary">
        Home
      </a>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Open Data
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../open-data/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/what-is-data.html" class="secondary">
            What is data?
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/what-can-data-not-do.html" class="secondary">
            What can data not do?
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/machine-readable-data.html" class="secondary">
            Machine-readable data
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/data-standards.html" class="secondary">
            Data standards
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/what-is-open.html" class="secondary">
            What is open?
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/beyond-open-data.html" class="secondary">
            Beyond open data
          </a>
        </li>
                <li class="secondary ">
          <a href="../open-data/open-data-in-the-philippines.html" class="secondary">
            Open data in the Philippines
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Data Literacy
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../data-literacy/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-literacy/what-is-data-literacy.html" class="secondary">
            What is data literacy?
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-literacy/what-is-data-literate.html" class="secondary">
            What does it mean to be data literate?
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        The Data Pipeline and Data-driven Projects
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/what-is-data-pipeline.html" class="secondary">
            What is the Data Pipeline?
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/define.html" class="secondary">
            Define
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/find.html" class="secondary">
            Find
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/get.html" class="secondary">
            Get
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/verify.html" class="secondary">
            Verify
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/clean.html" class="secondary">
            Clean
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/analyze.html" class="secondary">
            Analyze
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-pipeline-and-data-driven-projects/present.html" class="secondary">
            Present
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group active">
      <a href="" class="primary">
        Making Better Data Presentations
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary active">
          <a href="design-principles.html" class="secondary">
            Design Principles
          </a>
        </li>
                <li class="secondary ">
          <a href="things-to-consider-data-visualization.html" class="secondary">
            Things to consider
          </a>
        </li>
                <li class="secondary ">
          <a href="good-infographics.html" class="secondary">
            Making good infographics
          </a>
        </li>
                <li class="secondary ">
          <a href="exceptions.html" class="secondary">
            There are always exceptions
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Free and Open Source Tools
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../free-and-open-source-tools/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../free-and-open-source-tools/data-collection-tools.html" class="secondary">
            Data collection tools
          </a>
        </li>
                <li class="secondary ">
          <a href="../free-and-open-source-tools/data-analysis-and-presentation-tools.html" class="secondary">
            Data analysis and presentation tools
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Data Ethics
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../data-ethics/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-ethics/data-ethics.html" class="secondary">
            Ethical considerations with data
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Common Data Issues
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../common-issues/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../common-issues/data-fallacies.html" class="secondary">
            Data fallacies
          </a>
        </li>
                <li class="secondary ">
          <a href="../common-issues/open-data-misconceptions.html" class="secondary">
            Open data misconceptions
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Sharing and Opening Data
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../sharing-opening-data/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../sharing-opening-data/open-by-design.html" class="secondary">
            Open by design
          </a>
        </li>
                <li class="secondary ">
          <a href="../sharing-opening-data/co-creation.html" class="secondary">
            Co-creation
          </a>
        </li>
                <li class="secondary ">
          <a href="../sharing-opening-data/five-star-open-data.html" class="secondary">
            Five-star open data
          </a>
        </li>
              </ul>
          </li>
        <li class="primary group ">
      <a href="" class="primary">
        Building Data Culture
      </a>
            <ul class="secondary">
                <li class="secondary ">
          <a href="../data-culture/introduction.html" class="secondary">
            Introduction
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-culture/building-data-culture.html" class="secondary">
            Building a culture of data
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-culture/knowing-your-data.html" class="secondary">
            Knowing your data
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-culture/knowing-your-users.html" class="secondary">
            Knowing your users
          </a>
        </li>
                <li class="secondary ">
          <a href="../data-culture/data-socialization.html" class="secondary">
            Data socialization
          </a>
        </li>
              </ul>
          </li>
        <li class="primary  ">
      <a href="../other-resources.html" class="primary">
        Other Resources
      </a>
          </li>
      </ul>
</div>

<div id="livemark-topics">
  <div class="toc">
  </div>
</div>
</div>
<div id="livemark-main">
<div id="livemark-notes">
  Written in <a href="https://livemark.frictionlessdata.io" target="_blank"> Livemark </a><br>
  (2022-06-19 15:10)
</div>

<h1>Design Principles</h1>
<p>There are three basic design principles that you must be aware of when communicating visually with data—<strong>simplification, heirarchy, and layout</strong>.</p>
<h2>Simplification</h2>
<ul>
<li>Focus only on the things that matter.</li>
<li>Data can only represent a small part of reality. Don't try to put too many things in your visualization.</li>
<li>Avoid unnecessary clutter in your charts—but necessary clutter is fine.</li>
</ul>
<h2>Hierarchy</h2>
<ul>
<li>Some objects are more important than others. Reflect that in your visualizaton.</li>
<li>Utilize <strong>size</strong> - larger elements are more important than smaller elements.</li>
<li>Utilize <strong>contrast</strong> - elements that pop off the page are more important than muted ones.</li>
<li>Utilize <strong>positioning</strong> - our eyes usually follow a common pattern when reading a page, take advantage of that. All things being the same, people who read from left to right usually follow the “Z” path when looking at objects.</li>
</ul>
<h2>Layouts</h2>
<ul>
<li>Similar to positioning, use your layout to help users know where to look.</li>
<li>Portrait layout is good for documents and posters while a landscape is good for presentations.</li>
<li><strong>Proximity</strong> - elements placed close to each other will appear to be related.</li>
<li><strong>Enclosure</strong> - when you enclose things, you encourage the perception of these things belonging together.</li>
<li><strong>Separation</strong> - adding a line or space between elements makes them seem separated / disjoint.</li>
<li><strong>Connection</strong> - similar to enclosure, when you connect elements, you encourage the perception of these elements belonging to a group.</li>
<li>Be consistent - establish a style for each design element and use it for similar elements.</li>
</ul>
<div class="livemark-remark">
  <div class="alert alert-success" role="alert">
    See <strong>Graphic design has rules and they work</strong> (<a href="https://twitter.com/LaurelCoons/status/1533164215132987393">Laurel Coons</a>)<br><br><figure><img src="https://pbs.twimg.com/media/FUbkuj-X0AA5LmJ?format=jpg&amp;name=small"></figure>
  </div>
</div>

<div id="livemark-signs">
  <div>
        <div class="next">
      <a href="things-to-consider-data-visualization.html">
        Things to consider »
      </a>
    </div>
            <div class="prev">
      <a href="introduction.html">
        « Making better data presentations
      </a>
    </div>
      </div>
</div>
</div>
<div id="livemark-right">

<div id="livemark-rating">
  <iframe src="https://ghbtns.com/github-btn.html?user=benhur07b&amp;repo=data-literacy-101&amp;type=star&amp;count=true&amp;size=large" width="160px" height="30px" title="GitHub">
  </iframe>
</div>

<div id="livemark-about">
  <div>
    Learn about open data, how to work with data, how to do better data-driven projects, and how to improve your data literacy.
  </div>
</div>

<div id="livemark-links">
  <ul>
        <li>
      <a href="https://bnhr.xyz" target="_blank">
        BNHR
      </a>
    </li>
        <li>
      <a href="https://facebook.com/bnhr.xyz" target="_blank">
        BNHR Facebook
      </a>
    </li>
        <li>
      <a href="https://www.youtube.com/c/BNHRdotXYZ?sub_confirmation=1" target="_blank">
        BNHR YouTube (Subscribe)
      </a>
    </li>
        <li>
      <a href="https://www.twitter.com/BNHRdotXYZ" target="_blank">
        BNHR Twitter
      </a>
    </li>
        <li>
      <a href="https://bnhr.xyz/support" target="_blank">
        Donate and support
      </a>
    </li>
        <li>
      <a href="https://github.com/benhur07b/data-literacy-101/issues" target="_blank">
        Report
      </a>
    </li>
        <li>
      <a href="https://github.com/benhur07b/data-literacy-101/fork" target="_blank">
        Fork
      </a>
    </li>
        <li>
      <a href="https://github.com/benhur07b/data-literacy-101/edit/main/pages/better-data-presentations/design-principles.md" target="_blank">
        Edit
      </a>
    </li>
      
</ul></div>
</div>
<script src="https://unpkg.com/lodash@4.17.21/lodash.min.js"></script>
<script src="https://unpkg.com/jquery@3.6.0/dist/jquery.min.js"></script>
<script src="https://unpkg.com/popper.js@1.16.1/dist/umd/popper.min.js"></script>
<script src="https://unpkg.com/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script>
<script src="https://unpkg.com/prismjs@1.23.0/components/prism-core.min.js"></script>
<script src="https://unpkg.com/prismjs@1.23.0/plugins/autoloader/prism-autoloader.min.js"></script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const content = document.querySelector("#livemark-main");
  const headings = content.querySelectorAll("h1, h2, h3, h4, h5, h6, h7");
  const headingMap = {};

  // Add identifiers
  Array.prototype.forEach.call(headings, function (heading) {
    const id = heading.id
      ? heading.id
      : heading.textContent
          .trim()
          .toLowerCase()
          .split(" ")
          .join("-")
          .replace(/[!@#$%^&*():]/gi, "")
          .replace(/\//gi, "-");
    headingMap[id] = !isNaN(headingMap[id]) ? ++headingMap[id] : 0;
    if (headingMap[id]) {
      heading.id = id + "-" + headingMap[id];
    } else {
      heading.id = id;
    }
  });

  // Add links
  Array.prototype.forEach.call(headings, function (heading) {
    const link = document.createElement("a");
    link.href = "#" + heading.id;
    link.innerText = "#";
    link.classList.add("heading");
    heading.appendChild(link);
  });
});

</script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const groups = $("#livemark-pages li.group");
  for (const group of groups) {
    $(group)
      .children("a")
      .click((ev) => {
        ev.preventDefault();
        $(group).toggleClass("active");
        // $(group).find(".fa").toggleClass("fa-chevron-right");
        // $(group).find(".fa").toggleClass("fa-chevron-down");
      });
  }
});

</script>
<script src="https://unpkg.com/tocbot@4.12.3/dist/tocbot.min.js"></script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  // Start tocbot
  tocbot.init({
    // Where to render the table of contents.
    tocSelector: ".toc",
    // Where to grab the headings to build the table of contents.
    contentSelector: "#livemark-main",
    // Which headings to grab inside of the contentSelector element.
    headingSelector: "h2",
    // For headings inside relative or absolute positioned containers within content.
    hasInnerContainers: true,
    // Called each time a heading is parsed. Expects a string in return.
    headingLabelCallback: (label) => label.replace(/(^#|#$)/g, "").trim(),
    // Disable generating ordered lists (ol)
    orderedList: false,
    // Fix active link class
    onClick: syncList,
    scrollEndCallback: syncList,
  });

  // Style list
  $("#livemark-topics .toc > ul").addClass("primary");
  $("#livemark-topics .toc > ul > li").addClass("primary");
  $("#livemark-topics .toc > ul > li > a").addClass("primary");
  $("#livemark-topics .toc ul.is-collapsible").addClass("secondary");
  $("#livemark-topics .toc ul.is-collapsible li").addClass("secondary");
  $("#livemark-topics .toc ul.is-collapsible li > a").addClass("secondary");
  for (const element of $("#livemark-topics .primary")) {
    if ($(element).find(".secondary").length) {
      $(element).addClass("group");
    }
  }

  // Sync list
  function syncList() {
    for (const element of $("#livemark-topics li.primary")) {
      if ($(element).find(".is-active-li").length) {
        $(element).addClass("is-active-li");
      }
    }
  }
  syncList();
});

</script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const handlePopstate = async () => {
    const href = location.hash;
    if (href.startsWith("#card=")) {
      const code = href.split("=")[1];
      const response = await fetch(`/assets/cards/${code}.html`);
      const html = await response.text();
      $("#livemark-cards .modal-title").html("");
      $("#livemark-cards .modal-body").html(html);
      $("#livemark-cards h1").appendTo("#livemark-cards .modal-title");
      $("#livemark-cards .modal").modal();
      $("#livemark-cards .modal").on("hidden.bs.modal", () => {
        history.pushState("", document.title, window.location.pathname);
      });
    }
  };
  window.addEventListener("popstate", handlePopstate);
  handlePopstate();
});

</script>

<div id="livemark-cards">
  <div class="modal fade" tabindex="-1" role="dialog">
    <div class="modal-dialog modal-lg" role="document">
      <div class="modal-content">
        <div class="modal-header">
          <h5 class="modal-title"></h5>
          <button type="button" class="close" data-dismiss="modal" aria-label="Close">
            <span aria-hidden="true">×</span>
          </button>
        </div>
        <div class="modal-body">
        </div>
        <div class="modal-footer">
          <button type="button" class="btn btn-secondary" data-dismiss="modal">Close</button>
        </div>
      </div>
    </div>
  </div>
</div>
<script src="https://unpkg.com/ue-scroll-js@2.0.2/dist/ue-scroll.min.js"></script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  // Init
  const readability = localStorage.getItem("livemark-display-readability");
  if (readability === "plus") {
    document.body.classList.add("with-readability");
  } else {
    document.body.classList.remove("with-readability");
  }

  // Plus
  document
    .getElementById("livemark-display-plus")
    .addEventListener("click", function () {
      document.body.classList.add("with-readability");
      localStorage.setItem("livemark-display-readability", "plus");
    });

  // Minus
  document
    .getElementById("livemark-display-minus")
    .addEventListener("click", function () {
      document.body.classList.remove("with-readability");
      localStorage.setItem("livemark-display-readability", "minus");
    });

  // Print
  document
    .getElementById("livemark-display-print")
    .addEventListener("click", function () {
      window.print();
    });

  // Scroll
  const scrollSpeed = parseInt("10");
  UeScroll.init({ element: "#livemark-display-scroll .fa", scrollSpeed });
});

</script>

<div id="livemark-display">
  <div class="control" id="livemark-display-print" title="Print">
    <span class="fa fa-print"></span>
  </div>
  <div class="control" id="livemark-display-plus" title="Increase readability">
    <span class="fa fa-plus"></span>
  </div>
  <div class="control" id="livemark-display-minus" title="Decrease readability">
    <span class="fa fa-minus"></span>
  </div>
  <div class="control" id="livemark-display-scroll" title="Back to top">
    <span class="fa fa-chevron-up"></span>
  </div>
</div>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const container = $(".livemark-infinity");
  if (container.length) {
    const elements = container
      .children()
      .map((index, element) => element.outerHTML)
      .get();
    container.html(elements.splice(0, 100));
    container.show();
    window.addEventListener("scroll", () => {
      const element = container.get(0);
      const position = window.scrollY + window.innerHeight + 100;
      const threshold = element.offsetTop + element.scrollHeight;
      if (position > threshold) {
        container.append(elements.splice(0, 100));
      }
    });
  }
});

</script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const left = document.getElementById("livemark-left");
  const mobile = document.getElementById("livemark-mobile");
  mobile.addEventListener("click", () => {
    left.classList.toggle("active");
    mobile.classList.toggle("active");
  });
  // NOTE: We can replace the selector by 'a:not[href=""]' after #57
  left.querySelectorAll("li:not(.group) a").forEach((link) => {
    link.addEventListener("click", () => {
      if (left.classList.contains("active")) {
        left.classList.remove("active");
        mobile.classList.remove("active");
      }
    });
  });
});

</script>

<div id="livemark-mobile">
  <div class="stack" title="Toggle menu">
    <span class="bar"></span>
    <span class="bar"></span>
    <span class="bar"></span>
  </div>
</div>
<script src="https://unpkg.com/paginationjs@2.1.5/dist/pagination.min.js"></script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const container = $(".livemark-pagination");
  if (container.length) {
    const elements = container
      .children()
      .map((index, element) => element.outerHTML)
      .get();
    container.html(`
      <div class="livemark-pagination-data"></div>
      <div class="livemark-pagination-navs"></div>
    `);
    container.find(".livemark-pagination-navs").pagination({
      dataSource: elements,
      callback: (html) => {
        container.find(".livemark-pagination-data").html(html);
      },
    });
    container.show();
  }
});

</script>
<script src="https://unpkg.com/lunr@2.3.9/lunr.min.js"></script>
<script src="https://unpkg.com/jquery-highlight@3.5.0/jquery.highlight.js"></script>
<script src="https://unpkg.com/jquery.scrollto@2.1.3/jquery.scrollTo.js"></script>
<script>

document.addEventListener("DOMContentLoaded", function () {
  const prepare = () => {
    const searchParams = new URLSearchParams(window.location.search);
    const query = searchParams.get('query') || ''
    if (query.length >= 3) {
      searchInput.value = query
    }
  }
  const search = () => {
    unhighlight()
    query = searchInput.value
    searchOutput.innerHTML = ''
    searchOutput.style.visibility = 'hidden'
    const searchParams = new URLSearchParams(window.location.search);
    if (query.length < 3) return
    const results = searchIndex.search(query)
    if (!results.length) return
    searchParams.set('query', query)
    const newRelativePathQuery = window.location.pathname + '?' + searchParams.toString();
    history.pushState(null, '', newRelativePathQuery);
    const elements = []
    for (const result of results) {
      const item = searchItems[result.ref]
      const link = `${item.relpath}.html`
      const cls = window.location.pathname === link ? 'class="active"' : ''
      elements.push(`<li ${cls}><a href="${link}?query=${query}">${item.name}</a></li>`)
    }
    searchOutput.innerHTML = `<ul>\n${elements.join('\n')}\n</ul>`
    searchOutput.style.visibility = 'visible'
    highlight()
  }
  const highlight = () => {
    const stem = lunr.stemmer(new lunr.Token(query)).str
    $('#livemark-main').highlight(stem, {className: 'livemark-search-found'});
    setTimeout(() => {
      $(window).scrollTo($('.livemark-search-found').first(), 1000)
    }, 1000)
  }
  const unhighlight = () => {
    $('#livemark-main').unhighlight({className: 'livemark-search-found'});
  }
  const searchItems = {
          'index': {
          'name': 'Data Literacy 101',
          'path': 'index',
          'relpath': '../../index',
          'text': "# Data Literacy 101 ## About the website This website aims to present, introduce, and provide a general overview of the fundamentals of data literacy in a way that is approachable and easy to understand. The fields of data and data literacy are vast and this website represents only a fraction of all the available knowledge and information. Be that as it may, the author hopes that this will serve as a good starting point for anyone interested in learning about open data, data literacy, and how these concepts can be applied in the work that they do. ### Using the website You can use the website as a general reference. It is divided into modules that discuss common topics in the field of data literacy and provides links to other learning resources. ```yaml remark type: success text: Notes, reminders, and additional information are commonly found in Green boxes. ``` ```yaml remark type: primary text: Questions for you to think about or ponder on are commonly found in Blue boxes. ``` ```yaml remark type: warning text: Warnings and gotchas are commonly found in Yellow boxes. ``` ## About me I am free and open stuff advocate from the Philippines who works at the intersections of the openness, data, technology, and geospatial fields. I am an alumnus of the [School of Data](https://schoolofdata.org) Fellowship and Data Expert Programme with 8+ years of experience providing training, support, and consulting services on data literacy and free and open source software for geospatial (FOSS4G) applications to individuals, government agencies, the private sector, and civil society. I support and take an active role in the open data and open mapping communities in the Philippines as an individual and through [BNHR](https://bnhr.xyz), my open data and open geospatial consultancy, and SmartCT, a tech non-profit that I co-founded. You can find me online on my [website](https://bnhr.xyz/) and on [Facebook](https://facebook.com/bnhr.xyz), [YouTube (subscribe)](https://www.youtube.com/c/BNHRdotXYZ?sub_confirmation=1), [Twitter](https://www.twitter.com/BNHRdotXYZ), and [Mastodon](https://mastodon.social/@benhur07b). ## Support BNHR If you find these materials useful, you can consider donating to the cause or buying me a drink below. ## License Except when expressly provided, this work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/). You are free to: **Share** \u2014 copy and redistribute the material in any medium or format **Adapt** \u2014 remix, transform, and build upon the material Under the following terms: **Attribution** \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. **ShareAlike** \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original. Other works (images, media, software, etc.) referenced in this work are under their own respective licenses.",
      },
          'pages/open-data/introduction': {
          'name': 'Open data',
          'path': 'pages/open-data/introduction',
          'relpath': '../open-data/introduction',
          'text': "# Open data ## What is this module about? This module will introduce the basic concepts of data and openness as well as provide some context about the state of open data in the Philippines. ## Learning objectives At the end of this module, you should be able to: - Define openness, data, and open data - Understand the importance of open data, machine-readability, and data standards - Differentiate between human and machine-readable data - Identify the limitations of data - Think about how you can utilize open data - Think about the state of open data in the Philippines",
      },
          'pages/open-data/what-is-data': {
          'name': 'What is data?',
          'path': 'pages/open-data/what-is-data',
          'relpath': '../open-data/what-is-data',
          'text': "# What is data? \u003e \u201cData may be thought of as **unprocessed atomic statements of fact**.\u201d ([Open Data Handbook](https://opendatahandbook.org/glossary/en/terms/data/)) The definition above is just one of the many definitions that you will find if you search for the meaning of data. We all have an instinctive sense of what data is but if you ask different people to define it, you will get different answers. That much is sure. Now even though not having a singular definition does not prevent us from properly using data, when we are just starting to learn about data, it is important that we have a clear definition that we can agree on. For this module, aside from the definition from the Open Data Handbook, we will also define data as **structured representations of the world**. ## A structured representation of the world ```yaml remark type: success text: In this website, a data point refers to individual elements collected about reality (i.e. age being one data point about a a person) while a dataset refers to a collection of data points (i.e. a dataset can include a person\u0027s age, name, address, etc.). ``` Data is **structured** because it follows logical and well-defined rules as to how it is stored or presented. It is this structure that differentiates data from other pieces of information such as a textual description. For example, the statement \"Jose is a 35-year-old male living in Pampanga.\" can be restructured into a table with fields for ```name``` (Jose), ```age``` (35), ``sex`` (male), and ``location`` (Pampanga). Data is a **representation of the world** because it tries to capture a part of reality. It is important to remember that no matter how large of a dataset you gather, it is always almost impossible to represent reality in its entirety. This is why it is important in any data project to always [verify](../data-pipeline/verify.html) if the data that will be used and the outcomes from analyzing the data are valid and appropriate. There are several ways to do this which include getting expert advice, consulting the source of the data, and performing preliminary statistical analysis. **Non-structured representation** Jose is a 35-year-old single male living in Pampanga while Maria is a 29-year-old married female living in Antique. **Structured representation** ```yaml table data: [{\"name\": \"Jose\", \"age\": 35, \"civil status\": \"single\", \"sex\": \"male\", \"location\": \"Pampanga\"}, {\"name\": \"Maria\", \"age\": 29, \"civil status\": \"married\", \"sex\": \"female\", \"location\": \"Antique\"}] width: 720 columns: - data: name - data: age - data: \"civil status\" - data: sex - data: location ``` ```yaml remark type: warning text: Structured and unstructured data may have different definitions in other fields such as data science. ``` ```yaml remark type: warning text: It is not always true that structured = quantitative and non-structured = qualitative. For example, you can have a structured dataset of qualitative information. ``` ## Classifications of data There are several ways to classify data and the more you work with data, the more you will be familiar with these classifications. One of the most common ways that data is classified is whether it provides **quantitative** or **qualitative** information. Data as a term is used in multiple ways in multiple disciplines. In casual conversations, data is often used interchangeably with information while in a more technical or scientific setting, data pertains to information collected in a structured way. Specifically: **Qualitative data** is data that refers to the quality of something: the name of a person, the name of a company, a description of experiences are all qualitative data. It can be unstructured (e.g. interview transcription) or structured (e.g. a table organizing information from the interview). **Quantitative data** is data that refers to a number\u2014e.g. the age of a person, the number of bidders for a project, the amount of the winning bid are all quantitative data. Data can also be classified based on the **type of information** it holds. For example: **Numerical data** uses numbers to hold information. They can further be classified into: - **Discrete data** which is numerical data with distinct values or gaps between them. These usually come in the form of counting numbers or integers. Examples include the number of bidders for a government project, the age of a person in years, or the number of correct answers in an exam. - **Continuous data** which is numerical data with a continuous range. These usually take the form of rational numbers. Examples include the height of a person, the length of your foot in cm or inches as opposed to your shoe size which is discete, or the amount of the winning bid for a government project. **Categorical data** puts the object being described into a category. In the case of Jose and Maria, their civil status and sex are categorical data about them. Other types of data that you may encounter are: **Geographic or Spatial data** that hold information connected to a particular place or location and **Time-series data** which holds information about the value/state of a particular thing over time. ```yaml remark type: primary text: Think of a common dataset that you use at work (or common information that you gather), how do you classify these information? Are they numerical, categorical, spatial, or maybe some other kind of data? ``` ## The value of data Gaining wisdom from data by the Information Factory You have probably encountered the diagram above from the [Information Factory](https://www.theifactory.com/news/gaining-wisdom-from-data/) before. It illustrates that it is not the data per se that has value but it is what you do with the data that counts. - **Data** starts as seemingly random dots that could represent anything. - **Information** is generated when meaning and attributes are attached to the raw data indicated by applying different colors to the dots. - **Knowledge** is gained when the dots start to make sense and connections between the different pieces of information can be made. - **Insight** is when knowledge become synthesized in order to obtain a deeper understanding of the data or the problem\u2014i.e. identifying the two most important dots in the set. - **Wisdom** is then the ability to use insight in order to facilitate informed decision making\u2014i.e. finding the best path between two dots. **Data is valuable** not because it is data but **because of the things that we can gain from it**. ```yaml remark type: primary text: Let\u0027s play a game:I have a box in front of me.The box is large and heavy.There\u2019s a door in front of the box which I can open.A light comes on when I open the door.The inside of the box is colder than the outside.There is usually food inside the box.The box is usually found in the kitchen.There are usually things put on top of the box.What is the box? ``` At some point in the game above, you managed to connect the different pieces of information (knowledge) to formulate a hypothesis (insight) about the box. By combining these pieces of information together, you are able to arrive at an informed decision about what the box is. If you guessed refrigerator, then you are right. However, did you ever think about the fact that this answer\u2014that the box is a refrigerator\u2014only makes sense because we live in a society that knows what a refrigerator is and its characteristics? If you show the same set of statements to people who have never seen or heard of a refrigerator, would they give you the same answer? This brings us to our next point about the value of data: **data is only valuable when put in the proper context**. This means that the data you use to solve one problem may not be useful for solving a different problem or even the same problem in a different context. This is why it is imperative in any data-driven project that we properly [define the problem we are trying to solve](../data-pipeline/define.html) before proceeding with gathering, analyzing, or visualizing the data. Data also becomes **valuable when you can turn data into action**. Here it is important to note that we cannot act on what we cannot measure. This is why [finding](../data-pipeline/find.html) and [getting](../data-pipeline/get.html) the appropriate data is important if we plan to make data actionable. ## The (ab)use of data - Data is a resource (such as energy, oil, people) and like any resource, data is susceptible to both use and abuse. - Data can and will lie. See: [Data fallacies](../common-issues/data-fallacies.html) - [Data ethics](../data-ethics/introduction.html) should be an integral consideration in any data activity especially those that have the potential to affect people and communities directly or indirectly. The way that data is collected, shared, and used should consider issues such as openness, consent, bias, and privacy. ## The field of data is far too important to be left to data scientists Because of the ubiquity, value, usefulness, and susceptibility for abuse of data, it is imperative that everyone is involved in the conversations around data. In order to fulfill the promise and potential that data has to offer, a data literate citizenry is needed where everyone\u2014civil society organizations, businesses, local governments, journalists, citizens\u2014understands what data is and uses it effectively to perform their civic duties and participate in society. This is where [data literacy](../data-literacy/introduction.html) comes in. The field of data should be inclusive and no single person, department, or organization should have a monopoly on data because **the field of data is far too important to be left only to data scientists**. \u003e \"Data are like the stars. They are all around us even when we don\u2019t see them; when we do see them, they might seem incomprehensible but if we look hard enough, we can connect them to see patterns and constellations.\" (adapted from the answer of a participant from one of my Data Literacy training-workshops in South Cotabato when asked to explain the concept of data to a five-year old) ```yaml remark type: primary text: How about you? What is your own definition of data? ```",
      },
          'pages/open-data/what-can-data-not-do': {
          'name': 'What can data not do?',
          'path': 'pages/open-data/what-can-data-not-do',
          'relpath': '../open-data/what-can-data-not-do',
          'text': "# What can data not do? **Data**, even open data, **is not a panacea**. It is not something magical that can automatically solve problems for us. This is why it is equally important to talk about what data cannot do and the common misconceptions about data that beginner (and even experienced) data practitioners make. ## Data cannot give answers by itself Remember that data is oftentimes an [incomplete representation of the world](../open-data/what-is-data.html#a-structured-representation-of-the-world). Because of this, the outcomes of any data analysis or visualization should always be verified and validated to ensure that what the data is saying and what\u0027s actually happening are the same. This is particulary true when it comes to data models that try to predict real-world phenomena. When the model and the real-world do not agree, **don\u0027t be tempted to change the real-world to fit the model**. When answering questions and solving problems with data, it will not give you answers by itself but it will help you know where to look and what to focus on. You can think of data as witnesses to a mystery you are trying to solve. It is never wise to rely solely on one witness. You need multiple witnesses in order to corroborate and verify their accounts. At the same time, some witnesses may give you conflicting accounts. This is where you need to use your critical thinking and investigative skills in order to uncover the truth. ## Data cannot replace community building and engagement No matter how much data you gather about a community or about your data subjects, it cannot replace actual conversations with people. Building community and engaging with people builds trust. It also introduces you to possible biases that the community, you, and your data have. By [engaging with your data users](../sharing-opening-data/co-creation.html), you understand what they need from the data and how they need the data presented to them for it to be meaningful and understood. By knowing the audience, it becomes easier to communicate the data to them. Community building is an essential part of any data-driven project and one that can never be replaced by any amount of data. ## The end goal is not always a dashboard One of the most common mistakes that people new to data make is that they have a tendency to focus solely on the data and how they can present it. They think that because they have the data, they should use it and create visualizations from it. This shouldn\u2019t be the case. The creation of data visualizations, data platforms, and dashboards should not be the end-all be-all of a data-driven project. The primary goal of a data-driven project should always be to properly communicate its findings to its intended end-users. Sometimes this means creating data visualizations but sometimes it doesn\u0027t. A visualization may help but just because you create one does not mean that you get your message across clearer. In fact, most of the time, complex data visualizations and dashboards that are [improperly designed](../data-presentation-tips/introduction.html) and that did not go through consultations with the final data users actually waste the effort put into data collection and analysis. There\u2019s a saying that open data without users is just as bad as closed data. In the same manner, having a beautiful data visualization or dashboard without users is the same as having none at all. [A dashboard by any other name](https://www.civicsource.info/p/a-dashboard-by-any-other-name) by Katya Abazajian provides some good points about the use of dashboards by local leaders and how we might improve them. \u003e \"Dashboards aren\u2019t dead because they\u2019re not useful tools, but because they\u2019re a bandaid for lack of power and agency in local governing to solve big problems. They scratch at the surface of structural inequities repeatedly and without effect, like picking at a wound without ever allowing it to heal\" ([A dashboard by any other name](https://www.civicsource.info/p/a-dashboard-by-any-other-name) (Katya Abazajian, Civic Source)) \u003e \u201cData dashboards might be useful if they gave more grounded, truthful answers in the present and asked more creative, speculative questions about the future.\u201d ([A dashboard by any other name](https://www.civicsource.info/p/a-dashboard-by-any-other-name) (Katya Abazajian, Civic Source))",
      },
          'pages/open-data/machine-readable-data': {
          'name': 'Machine-readable data',
          'path': 'pages/open-data/machine-readable-data',
          'relpath': '../open-data/machine-readable-data',
          'text': "# Machine-readable data In the context of working with data, **machine-readable does not simply mean openable by a computer**. For files or formats to be considered machine-readable, they should allow for **easy extraction, processing, and analysis of the data that they contain**. The most common application of this is with tabular data. A simple test for machine-readability is if you can automatically compute for the average of tabular data stored on the file. You can do this easily with spreadsheets but not so much with word documents, PDFs, or images. Common examples of machine-readable formats for tabular data are: - Comma-Separated Value files os CSV (.csv) - Other Delimited Text Files (.tsv) - Spreadsheet files (.ods, .xls, .xlsx) - JavaScript Object Notation or JSON (.json) - Databases ```yaml remark type: success text: Because of recent advancements in technology, the line between traditional machine-readable and non-machine-readable file formats for tabular data is slowly disappearing. There are now applications that make it possible to directly extract and process tabular data from PDFs and images albeit not as easily as it is with spreadsheets. ``` ```yaml remark type: warning text: Machine-readable can have different meanings in other contexts. A file or format that\u0027s not normally considered machine-readable in one context may be considered machine-readable in another. For example, image files are not normally considered machine-readable if the purpose is to extract a table from the image but the same image may be considered as machine-readable for purposes of image analysis or pattern recognition. ``` ## Why is machine-readability important? ```yaml remark type: primary text: Consider this scenario:Juan and Pedro, persons of similar skill and capabilities, are both tasked with analysing the procurement activities of Procuring Entity A for the past 10 years.Juan is provided a PDF document containing the tables of A\u2019s procurement activities.Pedro was given the same dataset but in spreadsheet format.Who do you think will be able to provide answers faster and more accurately, Juan or Pedro? ``` Having machine-readable data allows data users to focus on creating knowledge, providing insight, and building solutions with the data instead of spending a lot of time converting data from one format to another. If also facilitates reusability of data and replicability of results. **Machine-readability is a prerequisite to having open and reusable data.** ## Converting non-machine-readable into machine-readable When working with data, it is often necessary to convert non-machine-readable files into machine-readable ones. This includes activities such as: - Extracting a table from a PDF - Getting a table from a webpage using web scraping tools - Digitizing hard copy documents and extracting the data from them This steps are usually done in the [get phase](../data-pipeline/get.md) of the [Data Pipeline](../data-pipeline/what-is-data-pipeline.html). ## Tidy data The [tidy data principles](https://kiwidamien.github.io/what-is-tidy-data.html) state that for data to be tidy, it must be stored such that: 1. Each variable forms a column, and that column contains one \"type\" of data 2. Each observation forms a row 3. Each type of observational unit forms a table There are multiple ways by which data can become untidy, [Hadley Wickham\u0027s paper on the subject matter](http://vita.had.co.nz/papers/tidy-data.pdf) identify these as: 1. Column headers contain values, rather than names 2. Multiple variables are stored in a single column 3. Variables are stored in both rows and columns 4. Multiple observational types are stored in a single table 5. A single observational unit is stored in multiple tables. Ensuring that data is tidy will help you easily identify: 1. The types or categories of data points, with one data point per column. Each type of information is described across multiple observations. 2. The individual observations, with one observation per row. An observation is a collection of data points made about a specific thing.",
      },
          'pages/open-data/data-standards': {
          'name': 'Data standards',
          'path': 'pages/open-data/data-standards',
          'relpath': '../open-data/data-standards',
          'text': "# Data standards ## What is a data standard? A **Data Standard** is a published specification or **set of rules** agreed upon by a **community of users** on **how data should be gathered, stored, and shared**. This can include rules on: - Structure of the file format used - Naming conventions - Common set of metadata fields ```yaml remark type: success text: It\u2019s important for a data standard to be agreed upon and used by a community of users because a data standard that\u2019s not followed by its users isn\u2019t much of a standard. ``` ## Why are data standards important? Data standards can improve **data interoperability** and **data quality**. ### Standards help interoperability Following a standard **prevents apples to oranges comparison** or the mistake of comparing two different datasets. For example, one dataset uses centimeters to record lengths while another uses inches, we can\u2019t just compare the values recorded in the two datasets. On the other hand, if we have two datasets that follow the same standard, then we can be sure that these datasets are compatible, meaning that a process or tool that was used for one dataset can safely be used for the other. Data standards are also important because almost all work we do with data requires us to use data from different sources and knowing how different datasets relate to each other can save us a lot of time. Standardization can help ensure that data is **compatible and comparable among different data users and providers** thus allowing everyone to realize mutual gains. ### Standards help with data quality Another thing that data standards improve is data quality. By having a standard, we are able to **separate the bad apples from the good apples**. By conforming to a standard, we make sure that our data is usable for its intended use. Standardization can help maintain the quality of our data and decisions by ensuring that **only data that meet certain criteria are considered and accepted**. ```yaml remark type: success text: Take the example of buying a new phone or laptop.By having a standard set of information for each item (e.g. price, battery life, storage space, RAM, camera specifications, etc.), we can easily compare them among each other and select the best one according to our needs.By knowing what standards these items meet, we can be confident about what we can expect from them. ```",
      },
          'pages/open-data/what-is-open': {
          'name': 'What is open?',
          'path': 'pages/open-data/what-is-open',
          'relpath': '../open-data/what-is-open',
          'text': "# What is open? \u003e \u201cOpen means **anyone can freely access, use, modify, and share for any purpose** (subject, at most, to requirements that preserve provenance and openness).\u201d ([The Open Definition](https://opendefinition.org/)) The Open Definition makes precise the meaning of **open** with respect to knowledge, promoting a robust commons in which anyone may participate, and interoperability is maximized. ## Openness means permission in advance - Openness ensures **people don\u2019t need to ask/request first**. - Free as in freedom; not just free food. - Openness means using an [open license](https://opensource.org/licenses). ### Un-examples of open data - An agency says they practice open data but you need to send a signed request letter first before getting access to the data. - An agency has an open data portal but the datasets aren\u0027t downloadable. - An agency releases open data but it can only be opened or used with proprietary software. - An agency releases open tabular data but in PDFs. ## Does open mean free? **Yes** but it may not be the kind of free that you are thinking of. ### Free as in Freedom The Open Definition matches that of **open** with respect to software as in the [Open Source Definition](https://opensource.org/osd) and is synonymous with **free** or **libre** as in the [Free Software Definition](https://www.gnu.org/philosophy/free-sw.en.html) and [Definition of Free Cultural Works](https://en.wikipedia.org/wiki/Definition_of_Free_Cultural_Works). When we talk about free and open data, we talk about **free as in freedom** not just the free in free food. Data is free and open because it gives you: - Freedom to access the data - Freedom to use the data - Freedom to modify the data - Freedom to share the data ```yaml remark type: warning text: One of the common misconceptions about open data is the fear that when an organization opens their data then it means people are free to modify that data and use it to misrepresent their organization. The freedom to modify data refers to a user editing a copy of the data to suit their needs (e.g. removing fields that aren\u0027t needed, adding new fields, computing averages, etc.). It does not refer to a user being able to modify the original copy of the data managed by the data source.In fact, having the data open makes it easier to verify if someone is misrepresenting it because others can easily refer to the original data source for verification. ``` ### The Free and Open Adobo Chicken abodo The **Free and Open Adobo** is a common analogy I use in order to talk about freedom and openness. If you are given a Free and Open Adobo, it not only gives you the freedom to eat the adobo but also the freedom to study how the adobo is made, the freedom to modify the adobo to suit your taste by adding seasoning or changing the recipe, and the freedom to share the adobo with your neighbor. Your neighbor also gets the same freedoms as you and they will be able to change the adobo to suit their taste. Imagine if we we aren\u2019t allowed to change adobo but merely eat what is given to us. How boring would life be? ## Why is openness important? There are a variety of reasons why openness in data is important\u2014from the philosophical to the practical and economic. Some of these reasons include: - **Transparency** - Data or it didn\u0027t happen. Open data can help fight misinformation by making sure that information that can be used to verify or debunk claims are readily available. - **Accountability** - Similarly, open data can help keep people and organizations honest and accountable to the claims and promises that they make. Open data can help build trust between different data actors. - **Ease of use and innovation** - It is easier to work with data that is already open than it is with closed data where the process of obtaining and securing the necessary permission to use the data is time-consuming. Open data also gives permission in advance to use the data which allows users to focus more on innovating and creating value from the data. ```yaml remark type: warning text: Data should not be thought of as a zero-sum game. More data for others does not mean less data for you. ``` ```yaml remark type: primary text: How about you? What is other reasons can you think of? ``` ## Is it enough that data is open? Although there are several ways to ensure that we [make the most of the data that we open and share](../sharing-opening-data/introduction.html), most data practitioners will tell you that simply having open data is not enough. There are a lot of external factors that can affect how useful open data is and how much actual impact it has. Additionally, our understanding of how data is used or can be used has evolved over the years and it is clear that open data is both simple and complex which poses unique challenges depending on the context where the concept of open data is used. In response to these challenges, we now have things like the FAIR (Findable, Accessible, Interoperable, Reusable) and CARE (Collective Benefit, Authority to Control, Responsibility, Ethics) principles of working with data and technologies such as Frictionless data that go [beyond just open data](../open-data/beyond-open-data.html).",
      },
          'pages/open-data/beyond-open-data': {
          'name': 'Beyond open data',
          'path': 'pages/open-data/beyond-open-data',
          'relpath': '../open-data/beyond-open-data',
          'text': "# Beyond open data ## Frictionless data The **Frictionless Data** project aims to reduce common data workflow issues (called *friction*) thus making working with data seamless, easy, and frictionless. It is a progressive open-source framework for building data infrastructure\u2014data management, data integration, data flows, etc.\u2014and includes various data standards and software to work with data. Frictionless can be used to describe data (add metadata and schemas), validate data, and transform data. Custom data standards can also be written based on the Frictionless specifications. For example, you can use Frictionless to: - easily add metadata to your data before you publish it. - quickly validate your data to check the data quality before you share it. - build a declarative pipeline to clean and process data before analyzing it. Learn more about [Frictionless data](https://frictionlessdata.io/introduction/). ## FAIR (Findable, Accessible, Interoperable, Reusable) principles \u003e The FAIR Guiding Principles for scientific data management and stewardship\u2019 intend to provide guidelines to improve the **Findability**, **Accessibility**, **Interoperability**, and **Reuse** of digital assets. \u003e \u003e The principles emphasise machine-actionability (i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention) because humans increasingly rely on computational support to deal with data as a result of the increase in volume, complexity, and creation speed of data. ([FAIR Principles](https://www.go-fair.org/fair-principles/), GO FAIR) Learn more about the [FAIR data principles](https://www.go-fair.org/fair-principles/). ## CARE (Collective Benefit, Authority to Control, Responsibility, Ethics) principles \u003e Existing principles within the open data movement (e.g. FAIR: findable, accessible, interoperable, reusable) primarily focus on characteristics of data that will facilitate increased data sharing among entities while ignoring power differentials and historical contexts. The emphasis on greater data sharing alone creates a tension for Indigenous Peoples who are also asserting greater control over the application and use of Indigenous data and Indigenous Knowledge for collective benefit. \u003e \u003eThe CARE Principles for Indigenous Data Governance are **people and purpose-oriented**, reflecting the **crucial role of data in advancing Indigenous innovation and self-determination**. These principles **complement the existing FAIR principles** encouraging open and other data movements to consider both people and purpose in their advocacy and pursuits. ([CARE Principles](https://www.gida-global.org/care), GLOBAL INDIGENOUS DATA ALLIANCE) Learn more about the [CARE principles for Indigenous Data Governance](https://www.gida-global.org/care).",
      },
          'pages/open-data/open-data-in-the-philippines': {
          'name': 'Open data in the Philippines',
          'path': 'pages/open-data/open-data-in-the-philippines',
          'relpath': '../open-data/open-data-in-the-philippines',
          'text': "# Open data in the Philippines ## The state of open data in the Philippines On paper, there should be a good open data ecosystem in the Philippines: 1. It is one of the [founding members of the Open Government Partnership (since 2011)](https://www.opengovpartnership.org/members/philippines/). 2. It has [adopted the Open Data Charter](https://opendatacharter.net/government-adopters/). 3. It ranked [22/100+ countries with a score of 55 in the 2016 Open Data Barometer](https://opendatabarometer.org/4thedition/?_year=2016\u0026indicator=ODB) which measures how governments are publishing and using open data for accountability, innovation and social impact. 4. It ranked [18/187 countries with the score of 73 in the 2020 Open Data Inventory](https://odin.opendatawatch.com/?year=2020) which measures how complete a country\u2019s statistical offerings are and whether their data meet international standards of openness. But if you ask most people about their experiences working with open data in the Philippines, they will tell you that it\u0027s difficult or there is none. The country has **no open data law** and its Freedom of Information (FOI) mandate comes in the form of an Executive Order (EO No. 2, series of 2016). Furthermore, it is not uncommon to see people and institutions hide behind the Data Privacy Law in order to avoid releasing documents, data, and information. It is not a stretch to say that there is a big disconnect between the state of open data on paper and actual state of open data in the Philippines. ### Open data and FOI Freedom of Information (FOI) and Open Data have **similar goals** but they are **not the same thing** (especially with how FOI is constructed right now in the country). ```yaml remark type: primary text: Think of what happens when you need to get data under FOI and under Open Data: ``` - **FOI is reactive or demand-driven.** Data is released only after a request is made and approved. - **Open Data is proactive or supply-driven.** Data is made available regardless of whether there is a request for it or not. - **Open data gives permission in advance.** Data users do not need to submit a request in order to access data. The barrier to data access is minimal to none. Be that as it may, it is important to understand that **open data and FOI are not adversaries** nor are they meant to replace one another. Rather they are **complementary tools** towards the same goal of building more transparent, trustworthy, and accountable institutions. There are instances where FOI is the better approach than open data and vice versa. ## Where can I find Philippine data? There are countless sources of Philippine data\u2014open or otherwise. I curate a repository known as [Awesome Data Philippines](https://bnhr.xyz/awesome-data-philippines/) where I list down data sources for the Philippines that I\u0027ve used or encountered such as Open Data Philippines and the Philippine Geoportal. I also have some [videos](https://www.youtube.com/playlist?list=PLwt-T7HCEV6fgs7EgHqtoR19qPLJ0596x) on how to access data from these data sources.",
      },
          'pages/data-literacy/introduction': {
          'name': 'Data literacy',
          'path': 'pages/data-literacy/introduction',
          'relpath': '../data-literacy/introduction',
          'text': "# Data literacy ## What is this module about? This module will introduce data literacy and cover aspects of the topic such as individual data literacy and organizational data literacy. ## Learning objectives At the end of this module, you should be able to: - Define what being data literate means for you - Explain the importance of data literacy - Be familiar with the different aspects of data literacy - Know the difference between individual and organizational data literacy",
      },
          'pages/data-literacy/what-is-data-literacy': {
          'name': 'What is data literacy?',
          'path': 'pages/data-literacy/what-is-data-literacy',
          'relpath': '../data-literacy/what-is-data-literacy',
          'text': "# What is data literacy? Similar to data, data literacy has a variety of definitions depending on who you ask and from what context they are coming from. [Gartner](https://www.gartner.com/en/information-technology/glossary/data-literacy), a corporate/business entity, defines data literacy as \"**the ability to read, write and communicate data in context**, with an understanding of the data sources and constructs, analytical methods and techniques applied, and the ability to describe the use case application and resulting business value or outcome.\" The [Harvard Business School Online](https://online.hbs.edu/blog/post/data-literacy) uses data literacy \"to describe an **individual\u2019s ability to read, understand, and utilize data in different ways**\". In fact, you will find a lot of conversations about data literacy that revolve around business and corporate interests. This \"corporate data literacy\" deals with topics such as upskilling the workforce, improving workplace productivity, increasing corporate performance, or using data to achieve commercial success such as in the Data Literacy Project which was founded by corporate entities such as Qlik, Accenture, Cognizant, Experian, etc. There are indeed a lot of opportunities for data literacy to grow in the corporate setting and big businesses can make strong allies for pushing the data literacy agenda but that doesn\u0027t mean that data literacy is confined to that space. In fact, data literacy can probably provide more value and impact to people outside the corporate world. In this website, although the topics and lessons can still be applied in a corporate setting, the focus is less about corporate data literacy but more about **data literacy in the civic space and the public sector**\u2014what does data literacy mean for government agencies, newsrooms, civil society organizations, and the general citizenry? This could be learning how to read graphs and charts appropriately, how to draw correct conclusions from data, and how to recognize when data is being used in misleading or inappropriate ways. As such, **data literacy itself deeply connected to other literacies** such as statistical literacy which is the ability to make sense of statistics such as surveys and polls; visual literacy whcih is the ability to understand information presented visually in the form of charts and graphs; media literacy which is the ability to critically analyze the information consumed in different forms of media and also a powerful tool against disinformation; and algorithm literacy which involves understanding how algorithms influence people\u0027s lives and their effects on society. We look at **data literacy as a means to advance and protect safe, fair, and free societies**. Because of the ubiquity of data and how embedded it has become in our everyday lives, data literacy has also become synonymous with our ability to effectively participate in today\u0027s society. It is an indespensable skill that allows us to navigate a society where data has become a key element in our interactions\u2014not just physically but moreso digitally. In order to do so, we must build people\u0027s data literacy. This not only means empowering people with data skills but more importantly putting mechanisms and structures in place that will provide them the confidence to interact with data and a safe environment to improve and share their work. Building data literacy should be inclusive so that no single person, department, or organization would have a monopoly on data or data work. ```yaml remark type: success text: You can think of data literacy as a foundational requirement in order to maximize the impact and value of data to ensure safe, inclusive, and equitable societies. ```",
      },
          'pages/data-literacy/what-is-data-literate': {
          'name': 'What does it mean to be data literate?',
          'path': 'pages/data-literacy/what-is-data-literate',
          'relpath': '../data-literacy/what-is-data-literate',
          'text': "# What does it mean to be data literate? **It depends on you.** As mentioned previously, data literacy can mean different things to different people. ## Individual/personal data literacy At its most basic, a person\u0027s data literacy can be thought of as their ability to read, write, understand, communicate, and work with data in different ways. In this sense, individual data literacy is very similar to having data skills. However, it is important to remember that **data literacy is not just about having data skills\u2014especially highly technical data skills**. These highly technical data skills such as data analytics or data science form only a very small part of data literacy. One good thing about individual data literacy and individual data skills being similar is that it makes it easier to build and improve individual data literacy. For example, one of the best ways to build your data literacy is to learn the [Data Pipeline](../data-pipeline/introduction.html) and using it for [doing data-driven projects](../data-driven-projects/introduction.html). ## Organizational data literacy Organizational data literacy is a bit more complex and harder do build. Factors such as **leadership, vision, internal processes and mechanisms all have an effect on an organization\u0027s data literacy journey**. Individual data skills of organization members are not\u2014and should not be\u2014the end-all-be-all of what it means to be a data-literate organization. From an organizational perspective, some of the people who take part in building data literacy and fostering data culture in an organization will have no analytic interactions with data and may never need to. The table belows shows an example of this: **different roles in an organization have different interactions with data and thus appreciate and utilize data differently**. | **Role** | **Data-related tasks and interactions** | |------------------------------|--------------------------------------------------------------------------------| | Manager | strategic planning, staff and organization development | | Marketing \u0026 Communications | data analysis and narratives for storytelling, branding, and fundraising | | IT | assess and support data products, provide infrastructure for data-related work | | Training \u0026 Capacity Building | provide learning opportunities, workshops, and technical training | | Community | get and provide data, help/services, feedback | Going further, we can say that a data literate or data-ready organization isn\u0027t just one that has the most number of data analysts or data scientists but one that: - Uses [data as evidence](../data-culture/building-data-culture.html) for evidence-based decision making; - Uses [data ethically](../data-ethics/data-ethics.html); - Builds and fosters [data culture](../data-culture/introduction.html) within the organization; - [Knows its data](../data-culture/knowing-your-data.html) and its [data users](../data-culture/knowing-your-users.html); and - Empowers its members to learn, improve, and share their data skills and knowledge through activities such as [data socialization](../data-culture/data-socialization.html). ```yaml remark type: primary text: How about you?How would you describle your data literacy and your organization\u0027s data literacy?How do you interact with data in your role in your organization? What other skills do you think you need?Are there mechanisms in place for you to learn these skills within or outside your organization? ```",
      },
          'pages/data-pipeline-and-data-driven-projects/introduction': {
          'name': 'The Data Pipeline and Data-driven projects',
          'path': 'pages/data-pipeline-and-data-driven-projects/introduction',
          'relpath': '../data-pipeline-and-data-driven-projects/introduction',
          'text': "# The Data Pipeline and Data-driven projects ## What is this module about? This module will introduce the Data Pipeline and its application to data-driven projects. ## Learning objectives At the end of this module, you should be able to: - Understand how the Data Pipeline works and how it can be applied in doing data-driven projects - Know the steps of the Data Pipeline - Identify the key aspects and common issues when using the Data Pipeline for data-driven projects",
      },
          'pages/data-pipeline-and-data-driven-projects/what-is-data-pipeline': {
          'name': 'What is the Data Pipeline?',
          'path': 'pages/data-pipeline-and-data-driven-projects/what-is-data-pipeline',
          'relpath': '../data-pipeline-and-data-driven-projects/what-is-data-pipeline',
          'text': "# What is the Data Pipeline? The [Data Pipeline](https://schoolofdata.org/methodology/) is an approach developed by the School of Data network to work with data from beginning to end. Aside from being a flexible guide for doing data-driven projects, it is also a wonderful tool for teaching how to work with data to beginners and experienced data practitioners alike as it divides the process into understandable and manageable steps. It is simple enough for beginners to grasp yet open enough for experienced practitioners to play around with. The Data Pipeline is an ever-improving, dynamic tool that has been utilized, extended, and improved upon by countless data practioners over the years. Its current steps are: - **Define** - **Find** - **Get** - **Verify** - **Clean** - **Analyze** - **Present** ```yaml remark type: success text: Although the Pipeline is a template, it should not be thought of as a rigid one. It is designed to be easily adaptable to different contexts and you shouldn\u0027t be afraid to experiment with it. ``` ```yaml remark type: success text: It is also important to note that the process of using the Data Pipeline is not always linear\u2014you may need to do the find and get steps multiple times or repeat the verify and clean steps if you find mistakes in the outcome of your analysis. ``` The Data Pipeline (2022)",
      },
          'pages/data-pipeline-and-data-driven-projects/define': {
          'name': 'Define',
          'path': 'pages/data-pipeline-and-data-driven-projects/define',
          'relpath': '../data-pipeline-and-data-driven-projects/define',
          'text': "# Define Data-driven projects always have a \u201cdefine the problem you\u2019re trying to solve\u201d component. It\u2019s in this stage you start asking questions and come around the issues that will matter in the end. Defining your problem means going from a theme to one or multiple specific questions that can be answered by data. Being specific forces you to think about the data you need and the kinds of analyses and presentations you need to do which then helps you to scope your project: Is the data needed easily available? Are there some key datasets that may be hard to get? ## Things to consider ### Formulating the Research Question(s) properly ```yaml remark type: success text: Important: A project does not need to be a \"research\" project to have a research question. ``` Data-driven projects are, by nature, investigative and seek to answer questions. If the end result of a project is a visualization or a dashboard, the research questions will help guide your thinking about what should be visualized or displayed on the dashboard. This is important because [data visualizations (e.g. dashboards) are meant to communicate information](present.html) and a dashboard that justs displays whatever data is available would be useless. If the result being sought is an advocacy campaign, then the research question will help focus on the message that the campaign aims to highlight. By starting with a question or questions, we also mitigate our tendency to design the project by based on a predefined answer or solution: yes, we know that COVID-19 affected procurement but we don\u0027t know the extent, duration, or impact of said effect. ### Identifying the scope and challenges of the project Since a data-driven project relies so much on data, it is important that the challenges related to data are identified and understood from the start. This includes challenges in finding or getting the data needed for the project such as an unresponsive or uncooperative government agency or doing data collection in remote areas. A properly formulated research question will highlight the scope of the project and the data needed, allowing you to get an initial understanding of the challenges involved in acquiring the data. ```yaml remark type: success text: For example, the theme \"impact of COVID-19 on public procurement in the Philippines\" can be broken down into:Question 1 - Are there significant differences between the prices of the commonly procured items during the pandemic and their prices pre-pandemic?Specific question 1.1 - What are the most commonly procured items during COVID-19?Specific question 1.2 - At what price are these items currently being procured?Specific question 1.3 - At what price were they being procured before COVID-19?Specific question 1.4 - Are there differences in the prices and are they significant? ``` ## Common issues ### Proceeding with a data-driven project without a research question A good research question helps guide the project in both output and scope. It is an essential element to understand what the project is aiming to accomplish. **A project can have several research questions but having none shows a lack of rigor or direction for the project.** ```yaml remark type: warning text: Typical consequences include:Dashboards designed around the data instead of the target audience.Delayed projects due to bad scope management.Difficulty to pivot the project if some of the expected data is not available. ``` ### Bad scoping Properly formulating research questions help with scoping the project in terms of the data needed. However, this will be for naught if you fail to account for other variables linked to the sources of data, its quality, and its accessibility. ```yaml remark type: warning text: Typical consequences include:Lack of anticipation of the difficulty of getting access to data held by a government agency, leading to delays in the project delivery.verestimation of the quality of the data held by governments, leading to a lowering of the ambition of the project.Not taking into account the logistical challenges of mobilizing stakeholders.Underestimating the time needed to clean a dataset manually, leading to delays and/or a less rigorous process.Not including the time needed to document properly the methodology. ```",
      },
          'pages/data-pipeline-and-data-driven-projects/find': {
          'name': 'Find',
          'path': 'pages/data-pipeline-and-data-driven-projects/find',
          'relpath': '../data-pipeline-and-data-driven-projects/find',
          'text': "# Find \u003e Where is the data located and is it accessible? This step entails knowing **where to look** for your data, finding it, and knowing how accessible it is. This is a step of **varying difficulty** depending on how well you defined your data problem. Finding data also depends on your **creativity and critical thinking**. When data seems hard to find, you can consider looking at **proxy indicators**\u2014an indirect measure or sign that indicates a phenomenon in the absence of a direct measure or sign. ## Things to consider ### Asking the right questions It is impossible for a single person to know where to find all the data that you need which is why experience, contextual knowledge, and having contacts in the relevant fields are key assets that will help you find the right dataset for your project. Be mindful of the fact that several sources may maintain similar datasets where one dataset is a better fit for some projects than others. Your task is to understand the precise data needs of your project in order to compare it with all the available data that you find. This step is important as it may lead your team to review the scope or research question of the project. When looking for data, you can: - Ask if there is a national government agency mandated to collect the data. - Ask if there are organizations or individuals who are working or have worked with the data. - Ask if there are any other datasets that can serve as indicators for the data needed? - Use online search engines (utilizing advanced search capabilities makes searching easier). - Use libraries and museums. ### Data sources There are a lot of tools, techniques, and data sources that can help you in finding data both online and offline. These include: - Data portals - Social networking sites - [Google advanced search operators](https://developers.google.com/search/docs/advanced/debug/search-operators/overview) - Google Dataset Search - FOI requests - Libraries and librarians - Museums and curators ```yaml remark type: primary text: What other sources can you think of? ``` ### Understanding data formats Different types of digital files use different structures to hold information. For example, a text file is structured differently than an image file, which is structured differently than a web page. At the same time, most computer applications can only open a few file types since they are programmed to work only with specific structures\u2014i.e. a word processor cannot open a spreadsheet file. **It is important that you know about different file formats and how they relate to the data that you require so that you can better plan a strategy on how to [get the data](get.html)**. Some of the most common file formats/file extensions that you might encounter when working with data include: - **.txt** - TXT is the extension for basic text files. It is not a structured data format per se, but it is possible to write data in a text file and have the right software recognize the structure despite the .txt extension such as in **delimited text files** (see CSV/TSV below). - **.csv/tsv** - CSV stands for Comma Separated Value and is used for storing tabular data: data arranged in rows and columns. An alternative is the TSV file format which uses tabs instead of commas to separate the values. Both of them are simply **text arranged in a structured way** The character used to separate values in the file (e.g. comma for CSV and tab for TSV) is known as the delimiter, hence the general name given to these kinds of files\u2014delimited text files. The .csv or .tsv extension indicates to the software how to read the file but many applications can automatically detect the tabular structure in delimited text files even without the .csv or .tsv extension. ```yaml remark type: success text: CSV is probably the most preferred file format for sharing tabular data. It is an open standard which means that you don\u0027t need proprietary or specialized software to open it. ``` - **.xls/.xlsx** - proprietary formats used by Microsoft Office to store its spreadsheets. Spreadsheets store tabular data similarly to CSV files but they also include information that is not purely data (e.g. the formulas used to compute cell values) and can store multiple tables in one file. As a consequence, spreadsheets are usually heavier (in terms of file size and the computing power needed to open them) than CSVs. Additionally, being a proprietary format might make .XLS and .XLSX less suitable for data sharing even if they have widespread use because of people\u0027s familiarity with Excel. - **.ods** - an open file format for spreadsheets developed and maintained as part of the Open Document Format for Office Applications (ODF). It is widely used in both free and open source office applications (LibreOffice, ONLYOFFICE) as well as propietary ones (MS Office). Being an open format means that there is no need to purchase a proprietary application in order to open and use it. - **.doc/.docx** - proprietary formats used by Microsoft Office to store word documents. They store more information (e.g. text formatting, images, links) than simple text files which makes them heavier to use. Similar to .XLS/.XLSX, they may be less suitable for data sharing even if they have widespread use because of people\u0027s familiarity with Word. - **.odt** - an open file format for word documents developed and maintained as part of the Open Document Format for Office Applications (ODF). - **JSON** - JavaScript Object Notation is designed to be lightweight, web-native, easy to read by programming languages, and easy to share through APIs. While JSON is an international standard like CSV, they store different types of data structures: CSV is designed for tabular data while JSON structures its data in a tree-like structure. The [Open Contracting Data Standard](https://standard.open-contracting.org/latest/en/) uses a JSON schema as its data model. - **GeoJSON** - JSON with accompanying location information\u2014i.e. coordinates (latitude and longitude), vector data model (point, line, polygon). It is useful for working with geospatial information on the web. - **shapefile** - a proprietary format for storing spatial vector data for ESRI products. Similar to .XLS, it is a well-known and widely-used format even if it has [limitations](https://bnhr.xyz/2018/12/12/i-choose-geopackage.html). - **geopackage** - an open format by the Open Geospatial Consortium for storing spatial data (both vector and raster) which has [can overcome the limitations of shapefiles](https://bnhr.xyz/2018/12/12/i-choose-geopackage.html). ```yaml remark type: success text: Tabular vs Tree structureWhen is each structure most appropriate? As a new data practitioner, the easiest data to deal with would be those that are stored in tabular format. This means that you know in advance how many columns/fields your dataset should have and that all data fit into these columns neatly.But what if you can\u2019t predict some part of your data? Take a list of public procurement bids. You may want to include, at minimum, the project name, the approved budget of contract, the procuring entity, the bid amount, and the bidders. But some projecs will have 2 bidders and others may have 30. To store this in a tabular format, you would have to compromise the quality or structure of your dataset:Either you store all bidders in one column, which will make analysis harderOr you add a lot of columns/fields in order to write one bidder per column and hope that the number of bidders will never go over the number of columns you set. You may end up with a dataset full of empty values/cells and a cumbersome amount of columns (which may or may not be needed).This is when a format like JSON that has a tree structure might be the better option. The tree format can associate an arbitrary number of values to each node/field. If the number of bidders from your first project differs from your second one, this will just change the number of branches linked to each node/field and not the number of nodes/fields in the data. Beyond their differences, both CSV and JSON are international open standards that are widely adopted, designed to be readable by humans without a need for software, and should be preferred over their closed alternatives. ``` ## Common issues ### Settling for a poor quality dataset When looking for data that you need, it is **not uncommon for you to find multiple datasets and sources** pertaining to the same data. Try to avoid the temptation to settle on the first dataset you find and adjust the project based on that without investigating further if there are better options. Sometimes it may be **more useful to create the needed dataset out of several quality datasets** rather than settling for the obvious choice.",
      },
          'pages/data-pipeline-and-data-driven-projects/get': {
          'name': 'Get',
          'path': 'pages/data-pipeline-and-data-driven-projects/get',
          'relpath': '../data-pipeline-and-data-driven-projects/get',
          'text': "# Get \u003e How do I get the data from its source/location into my computer/machine? Simply finding the data is not enough. Even if you know where to find the data, if you can\u2019t get a hold of the data, it will be useless. This step in the data pipeline involves getting the data from its initial location to your computer so that you can start working on it. This step can be short and easy or long and painful depending on variables such as data accessibility, availability, and the format that the data is in. Your goal for this step is to get data in a [machine-readable](../open-data/machine-readable-data.md) format. This often requires preparation time, including the time needed to research and locate the appropriate tools for the task. **Very rarely will data just be magically available to analyze.** ```yaml remark type: success text: A common roadblock faced by people looking for data is the lack of disclosure of data owned by government agencies or public institutions. If there is no open data that is easily accessible then your first step would be to ask for the data nicely. However, that doesn\u0027t always work. When that is the case, it is important to know if there is a law in your country that guarantees Freedom of Information (FOI) that will allow you to make a formal request for the data that you seek.It must be noted that even if an FOI request does not guarantee that you will get the data you seek, it is an important step that should not be ignored or forgotten. ``` ## Things to consider ### Understanding key terms and technologies It is important that you are at least familiar with terms such as: - **web scraping** - the automated retrieval information on a webpage - **pdf extraction** - automatically extracting data tables from PDF - **OCR (optical character recognition)** - allows the extraction of texts from images or scanned documents - **API (application programming interface)** - a way for people to query and request for information from a dataset/database Even if your team does not have the skills to use these techniques or technologies, you should make yourself aware of them in order to avoid trying to do things manually (a very common mistake which is also very error-prone) instead of getting someone to help. ### Methods of getting data If you are lucky and the data is readily available online in a digital format then you should be able to get the data directly. If not, you might need to request for the data or even extract the data from files and documents in order to convert them into a usable format. In the event that the data does not exist or you can\u0027t find sources for the data, you can do your own data collection. **1. Get the data directly** - downloading from open data portals - using an Application Programming Interface (API) to access the data **2. Request for the data** - sending an FOI request or a formal request letter to the data owner **3. Extract data from files and documents** - extract tables from PDFs using applications such as [Tabula](https://tabula.technology/) or Excalibur - scrape tables from webpages using Google Sheets, [webscraper.io](https://www.webscraper.io/), or programming with Python - extracting texts from scanned documents or images using OCR **4. Do the data collection yourself** - Manual pen-and-paper surveys - Using mobile data collection applicatiosn such as [ODK](https://getodk.org/)/[ODK-X](https://odk-x.org/), [KoBo](https://www.kobotoolbox.org/), or [Sabasi](https://sabasi.mobi/) - Crowdsourcing via social media or platforms such as mTurk and samasource ### Data collection Sometimes, no matter how hard you look, the data you need simply does not exist or is near impossible to find. When this is the case, you and your team may decide to collect the data yourselves. This data collection step can be simple or complex depending on the scope of the dataset that you want to build and the type of data needed. For a quick reference on how to on mobile data collection, you can refer to: https://school-of-data.github.io/mobile-data-collection/index.html ## Common issues ### Bad data collection methodology Data collection is often tricky to get right but doing it right\u2014and doing it right the first time\u2014is essential if you want to avoid delays and wasted effort. There are two common types of data collection projects: - The first one is similar to a desk research where the goal is to create a dataset out of multiple data points from different sources. This is usually done online. - The other one involves field data collection and requires you to send people with questionnaires to fill either by themselves (e.g. doing rapid damage assessment after a disaster) or with the answers from a respondent. | **Type of project** | **Common mistake** | **Best practice** | |------------------------|------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | Online data collection | Starting with researching and collecting the data | Defining the characteristics of the dataset you want to create (i.e. the columns of your spreadsheet) | | Online data collection | Not documenting the sources of the data | Creating a metadata file with the sources of all data; keeping untouched raw data in a separate folder | | Field data collection | Inconsistency born from the lack of instructions given to staff about how to deal with responses outside of the expectations | Defining a process that covers all possibilities. This could mean including standard non-response categories such as \u2018doesn\u2019t know\u2019 \u2018no response\u2019 \u2018alternative response\u2019 | | Field data collection | No anticipation of the analysis process in the methodology | Defining the analysis questions (see module 2.1) ahead of time in order to understand how the data should be structured | ### No policy for data storage, access, and protection No matter how large or how small the amount of data you need for a project, it is important that you idetify policies for the storage, access, and protection of the data. They do not need to be complex, but they should exist to will help ensure that you are prepared in case something bad happens with your data\u2014e.g. accidental deletion, computers getting lost or not working, etc. This can include policies about data redundancy and backups (where and when is the data backed up), who has access to what data, and how to keep sensitive data such as personally-identifiable information private and secure.",
      },
          'pages/data-pipeline-and-data-driven-projects/verify': {
          'name': 'Verify',
          'path': 'pages/data-pipeline-and-data-driven-projects/verify',
          'relpath': '../data-pipeline-and-data-driven-projects/verify',
          'text': "# Verify \u003e How bad is the data? All data are, in one way or another, bad. Similar to how rare it is to find data that just be magically available to analyze, it is **rarer to find good quality data that automatically fits your needs** (unless you are the one who collects the data but [that can also be problematic](get.html#bad-data-collection-methodology)). The verify step involves knowing how appropriate the data is for your project which you can do by checking the internal consistency, checking for outliers, and consulting the metadata when available. ```yaml remark type: success text: It is easy to get caught up and excited about doing your analysis the moment you get your data but you should always try to take the time first to include at least some verification. This simple action will help you avoid wasting time on bad data or, worse, publishing incorrect results. ``` ```yaml remark type: success text: Important: Do not delete data at this stage! ``` ## Things to consider ### Data trustworthiness, completeness, and quality **Data trustworthiness** refers to how much we can trust the data to represent what it says it does. How do you know if you can rely on what the data says? Data generated by a low quality or faulty sensor may not be trustworthy. A dataset collected by a professional survey enumerator may be more trustworthy than one collected by an amateur. Whether it is sensors or humans behind the data, assessing the trustworthiness of the data requires an understanding of the methodology and choices behind the creation of the dataset. **Data completeness** refers to how much the data covers the reality it tries to represent. A dataset may be incomplete because of inconsistent data collection practices or due to key elements being absent (a social survey dataset not recording gender will potentially deprive the data analysts of a real understanding of the social dynamics that the survey was trying to capture). Once again, understanding the methodology behind the data collection as well as the topic the dataset covers is essential to assess if the data is complete (enough). **Data quality** refers to how well the dataset is structured and documented. An example of a well-structured dataset is one that follows [tidy data principles](../open-data/machine-readable-data.html#tidy-data). Other principles will apply for non-tabular data such as JSON but someone working with this kind of data will most likely already know what they\u0027re doing. Quality can also refer to the documentation of the data. The minimum requirement for well-documented data is for it to have metadata. Data dictionaries, data inventories, and documentation about the collection and processind methodologies used are also relevant here. The more documented the data, the higher its quality since a properly documented dataset will allow you to check for its completeness and trustworthiness. ```yaml remark type: success text: Th metadata, data dictionary, and data inventoryThe metadata is the \"data about the data\". It can include every relevant contextual information about the dataset\u2014from the author, to the date of creation, to the expected format of the various values (text, numbers etc). A data dictionary can also be a part of the metadata. The metadata can be stored alongside the data (for example in a different tab of a spreadsheet) or shared alongside the dataset (ideally as a .json file, but most often as a .doc or .pdf file).A data dictionary or codebook is a document describing the meaning of all columns and values in a dataset. This is especially relevant for datasets that use abbreviated column headers and non-standard values. Sometimes the dictionary may skip obvious elements, such as the date column, although it may include it in order to describe the expected formatting of the values (e.g. DD-MM-YY or YYYY.MM.DD).A data inventory (or registry) is a document listing all the datasets owned by an organisation which can include all the datasets made publicly available by that organisation. A data inventory can also be thematic. In such a case, it may list down all relevant data sources across multiple organizations. For example, a data inventory of procurement-related data in the Philippines. ``` ### The four verification methods The four most common methods to perform verification of data are: **1. Asking the source:** the ones who produced or published the data are most likely the best experts on it. You should take advantage of this. Too often new data practitioners see themselves as having a one-on-one battle with the data. This should not be the case. It is not only highly inefficient but it also blinds you to your possible biases and prevents you from getting other perspectives about the data. **2. Asking experts:** data practitioners from the civic sector often get to work on datasets that pertain to many different topics with some topics being complex or outside their domain of expertise. It is important to remember that even if you might not be an expert on the topic, there is probably someone who is that you can reach and who can help you better contextualise the dataset for you. This is an essential step to take for any serious data project. Working with data is never an individual effort. **3. Statistical checks:** when exploring a large new dataset, diving in right away will probably result in confusion. Instead you\u2019ll want to make sure you understand what each column header means, what type of value to expect in the data, and if it fits what you have in mind. A common approach is to create a statistical summary of your data - calculating the mean, median, maximum (max), and minimum (min) values and standard deviation for key columns should give you a good idea of what the data looks like. You can also do some exploratory data analysis to look for possible errors or outliers in your data. **4. Common sense check:** This is probably the most important of all. It represents the ability to identify weird patterns or values in the dataset\u2014a sudden spike in population, negative values for the bid amount, a start date that is later than and end date. This relies on having a general sense for reading data but also good background knowledge about the context that the data is based on. This is why data skills are not sufficient to work with any and all kinds of data: the data needs to make sense to you and your context so that you won\u2019t miss important insights. ## Common issues ### No verification process Ideally, every new dataset must go through at least one of the four verification methods before it is used in the project. Of course, this isn\u0027t always followed. A lack of rigor and commitment to this process of data verification can lead teams to miss some inconsistencies in the data. At best, this leads to a painstaking backtracking process through the data pipeline. At worst, your team will just assume that the inconsistencies can be ignored. ```yaml remark type: success text: You may refer to The Quartz guide to bad data for an exhaustive reference to problems seen in real-world data along with suggestions on how to resolve them.",
      },
          'pages/data-pipeline-and-data-driven-projects/clean': {
          'name': 'Clean',
          'path': 'pages/data-pipeline-and-data-driven-projects/clean',
          'relpath': '../data-pipeline-and-data-driven-projects/clean',
          'text': "# Clean \u003e Just because data is dirty does not mean it\u0027s garbage. There is a common saying among people who work regularly with data that \"80% of the time spent working with data is spent cleaning it\" and indeed, it is often an arduous task that is not only time-consuming but can also be error prone. The CLEAN step of the Data Pipeline works as a group with the VERIFY and ANALYSE steps\u2014while simple datasets may only need to go through VERIFY, CLEAN and ANALYSE once, more complex datasets will see you go back and forth between the three. Specifically, you may find yourself: - cleaning the dataset a bit to be able to verify its content - going back to the verify step after finding something strange during the analysis - doing some basic analysis steps as part of the verification process ```yaml remark type: success text: Pristine data is very rare. Most of the time, the data you get will contain problems that you have to clean. ``` ## Things to consider ### Goals of data cleaning - create a consistent, human understandable, machine readable dataset - prepare the data for a specific analysis or visualization you want to use the data for ### Data cleaning steps Data cleaning can be broken down into three activities: **1. Data tidying** is the process of cleaning the structure of the data without touching its content and following the princples of [tidy data](../open-data/machine-readable-data.html#tidy-data). **2. Data editing** is the process of modifying the content of the data to prepare it for your analysis. This involves correcting problems with the values stored in the dataset. **3. Data consolidation** is the process of adding complementary data to your main dataset. This step provides an this is an opportunity to complement or extend the dataset that you have collected, verified and cleaned. The goal may be to produce a more complete analysis thanks to the addition of a new variable, or to simply consolidate in one dataset all the data that you will need to answer all your research questions. ```yaml remark type: warning text: Avoid deleting or overwriting the data in your original dataset. A better approach is to make copies of the data for each step of the data cleaning process or to utilize version control systems. ``` ```yaml remark type: warning text: Do not take a shortcut with data consolidation. The best practice is for you to go through the DEFINE, FIND, GET, VERIFY and CLEAN steps again with a new dataset before merging it with your main data. ``` ### Types of problems you might encounter There are two general kinds of problems with the data that you might encounter when cleaning it: **1. Formatting problems** - problems related to HOW the dataset is structured. These are usually resolved in the data tidying step. **2. Content problems** - problems related to WHAT is written or stored in the dataset. These are usually resolved in the data editing step. Examples of formatting problems include: | **Type of problem** | **Problem** | **Example** | **Suggested solution** | |---------------------|------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------| | Formatting problem | A single data point is stored in a multiple columns. | Address is saved as multiple columns of BARANGAY, MUNICIPALITY, and PROVINCE but you need it to be a single string | Concatenate values into a single cell | | Formatting problem | Separate data points are stored in a single column. | Address is saved as a single string of , , but you need to summarize data based on BARANGAY for your analysis. | Split the column into several columns | | Formatting problem | Multi-line or merged headers | Population data divided by age and sex where one row is used for age categories and another row is used for sex categories.**NOTE**: This might be useful for making data more human readable but it can easily become problematic for analysis purposes especially when using the data in applications that expect a single line header. | Convert the headers into a single line | Examples of content problems include: | **Type of problem** | **Problem** | **Suggested solution** | |---------------------|-------------------------------------------------------------|-----------------------------------------------------------------------------| | Content problem | Extra white spaces in the cell value | Trim/remove the extra white spaces. | | Content problem | Wrong or inconsistent use of case (lower, UPPER, CamelCase) | Convert the text to the case of choice (lowercase, UPPERCASE, Proper Case). | | Content problem | Spelling mistakes | Correct the spelling. You can use a spell checker. | | Content problem | Missing, incorrect, or blank values | Find, verify, and add the correct values. | ```yaml remark type: success text: You can always refer to The Quartz guide to bad data for an exhaustive reference to problems seen in real-world data along with suggestions on how to resolve them. ``` ```yaml remark type: primary text: What other formatting or content problems have you encountered when working with data? ``` ### Tools and techniques - **Spreadsheet applications** - LibreOffice Calc, Google Sheets, Microsoft Excel - **Specialized tools** - [OpenRefine](https://openrefine.org/) - **Programming** - Python, R, etc ```yaml remark type: success text: Which tool should I use?Stick with what you\u2019re comfortable with and try to start with the simplest tool first You don\u0027t need to dive directly to using specialized tools or programming. For most data work, using a spreadsheet application will be more than enough. ``` ```yaml remark type: success text: Best practices when cleaning dataAlways back-up your data.Make a copy for every step of the cleaning process (e.g. a tab in a spreadsheet for each step).Avoid deleting or overwriting data.There is no such thing as over-documentation. ``` ## Common issues ### Not keeping track of the history of modifications (i.e. version control) A lot of the data work done by with data deals with small datasets, processed in spreadsheets. Although spreadsheets are convenient, they do not provide a history of the modifications applied to the dataset, leading to problems if a mistake was made in the process. An easy way to address this is to create a new tab every time an important modification is applied to the data. This technique is especially useful for data cleaning. More tech-savvy data practitioners might use a version control system like GitHub or GitLab for the same purpose.",
      },
          'pages/data-pipeline-and-data-driven-projects/analyze': {
          'name': 'Analyze',
          'path': 'pages/data-pipeline-and-data-driven-projects/analyze',
          'relpath': '../data-pipeline-and-data-driven-projects/analyze',
          'text': "# Analyze \u003e What do I want to get from my data? Here we are! Data analysis is generally what comes to mind when we think about \"working with data\" but as you might have noticed, the actual analysis only comes at the end of a multi-step process. You will also find that **if you were able to do the previous steps of the pipeline correctly, the data analysis step becomes easy and trivial**. That is not to say that analysing data is always easy. Depending on the goals of your project and the data you have, it can also become something that only seasoned statisticians can undertake. Luckily, most of the analysis questions that you will encounter can be tackled with simple tools. If your questions look like \u2018who is most affected by X?\u2019 or \u2018how has Y evolved over the years?\u2019 then you will most likely be able to answer them yourself. If instead your question is of the \u2018is X influenced by Y\u2019 kind, then you will most likely need the help of someone with statistics training to help. ```yaml remark type: success text: You can think of the analysis step as you interviewing the data and the previous steps of the pipeline as preparation for the interview. Instead of a microphone, you will use a spreadsheet. Instead of questions, you have spreadsheet formulas. ``` ## Things to consider ### The type of analysis you need There are three general types of data analysis: **1. Descriptive analysis** that focuses on describing the basic features or characteristics of the data, such as the mean, the median, the maximum, the minimum, etc. **2. Inferential analysis** which allows you to make reasonable guesses about your data and how it relates to the larger dataset that it is part of or other datasets that are similar to itself. **3. Predictive analysis** is an advanced type of analysis where the goal is to make reasonable predictions about the probability of future or otherwise unknown events based on current or past data. ### Tools and techniques The kinds of tools and techniques you will use depends on your goals and data. If you are working mostly with tabular data in order to perform descriptive analysis, a spreadsheet application would suffice. The more complex or specialized your goals and data are, the more complex and specialized tools and techniques you would require. Some of these include: - **Programming languages** such as Python and R if you need complex, advanced, and automated computations. - **Databases and SQL** if you are dealing with large amounts of data and you need a scalable and robust storage + analysis solution. - **GIS and geospatial applications** if you are dealing with geospatial/location data, location is an important variable in your analysis, or you just want to make maps - **Statistical software** such as SPSS and Stata for more advanced statistical analysis. ```yaml remark type: success text: For a complex data project, a single tool may not be enough and you would need to use different kinds of tools and techniques to analyze your data. It\u0027s okay to seek help with tools that you may not be familiar with or are not comfortable using. ``` ### Using a hypothesis There are many ways to twist and turn the data to get some sort of answer but this should be discouraged or you run the risk of doing [data dredging](../common-issues/data-fallacies.html) instead of data analysis. Having a well-defined research question helps guide your analysis of the data and having hypotheses when doing your analysis helps you make sense of and interpret the results. Using a hypothesis makes you more deliberate with your analysis and prevents you from becoming arbitrary in your approach. Your hypothesis will tell you what to test/compute and how to interpret the results in the context of your project. It will tell you if the assumtions you made about your data or your project are valid. Additionally, even if the results of your analysis tells you to reject the hypothesis you made, this outcome is still interesting and significant because it means that the data does not say what you expected it to. The hypotheses you set can be based on previous analyses or expectations of what the data should show. ### Documenting the analysis Many teams rush to the analysis part and end up producing results that are hardly verifiable or reproducible because of the chaotic process they used to analyse the data. Documenting that process forces the analyst to organise their steps, and, sometimes, helps catch mistakes in the process. ### Making the analysis reproducible There are several ways for you to ensure that your project is reproducible such as following the [FAIR](../open-data/beyond-open-data.html#fair-findable,-accessible,-interoperable,-reusable-principles) principles or using technologies such as [Frictionless](../open-data/beyond-open-data.html#frictionless-data). Take note however that this isn\u0027t just limited to the analysis step of the data pipeline as reproducibility should be considered at all phases of your data-driven project\u2014e.g. planning for your project to be reproducible from the start. ## Common issues ## Not using hypotheses While a research question helps refine the direction and scope of a project, hypotheses help guide the data analysis. An insight generated from a data analysis can only make sense when replaced in the context of the topic being studied. What does it mean if, when studying public procurement, you find that 50% of contracts are won by only 10% of the total number of suppliers who submitted bids? Is it a lot or too little? Good or bad? Making a hypothesis (e.g. there is healthy competition when at least 25% of the suppliers win 50% of the contracts), based on past data or prevailing assumptions about the topic, helps frame the results of the analysis. Whether the hypothesis is verified or not, the results can now make sense. ## No documentation of the analysis steps You can never have too much documentation. This does not need to be overly verbose or complicated but should be complete and understandable enough to allow for the verification and review of the analysis steps or the reuse, replication, and reproduction of the steps in another project.",
      },
          'pages/data-pipeline-and-data-driven-projects/present': {
          'name': 'Present',
          'path': 'pages/data-pipeline-and-data-driven-projects/present',
          'relpath': '../data-pipeline-and-data-driven-projects/present',
          'text': "# Present \u003e Who is my audience, what message do I want to convey to them, and what is the best way for me to convey that message? Presenting data is all about thinking of your audience, the questions you set out to answer in your project, and the medium you select to convey your message or start your conversation. Often the presentation will require a graph of some sort but that\u2019s not always true. The first question that you have to ask yourself at this stage of the data pipeline is not \"how do I visualise the data?\" but rather \"what do I want my audience to get out of my project?\". Put another way, **the key parameters of data presentation are your audience and your message**. Once you\u0027ve properly identified the two, the process of selecting how you present the data should be easier\u2014*not necessarily easy per se*\u2014compared to if you didn\u0027t think about your audience and message. ```yaml remark type: success text: The use of the term data presentation instead of data visualization in the Data Pipeline is deliberate. The goal when working with data is to effectively present and communicate what the data says\u2014and that doesn\u0027t always require the use of a chart or graph. Similarly, as you might have noticed already, visualizations aren\u0027t exclusive to this step of the pipeline as they are also frequently used during data verification and analysis as well. ``` ## Things to consider ### The goals of the project What you want to achieve from the project will affect the way you will present data. Do you want to build a dashboard? Use it for an advocacy campaign? Help in the internal decision-making of your organization? Each of these will have different needs in terms of data presentation\u2014an advocacy campaign using street demonstrations may require the use of big, bold statistics written on signs to achieve maximum impact instead of a carefully crafted chart or graph. At the same time, you may choose to present the same dataset in different ways depending on your audience: - when using it in report, you may choose to include a table and a simple graph - when presenting it to a specialized or expert audience, you may prefer the use of more complex or interactive visualizations - when it\u0027s for the general public, you might want to create an infographic ### Put the audience first Always think about your audience when planning or creating your data presentation. If you can, consult and communicate with them at each step of your creative process. Show them your drafts, ask them for comments or suggestions to improve your messaging, do user-testing with a subset of your expected audience. At the end of the day, **the success of your data presentation is not up to you but to your audience**. ### Iterate to refine your visualization **Don\u0027t rush to publish a visualization** especially one that deals with complex and nuanced issues. Unless you are a data visualization expert with decades of experience, you will make mistakes or overlook some things on the first data visualization you create for a project. Don\u0027t be scared to iterate. This may take more time but it also means that the final data presentation you publish will be more robust and fit-for-purpose. ### Choosing your visualization **Different visualizations have different strengths and weaknesses**\u2014some work best with categorical data while others specialize in showing trends in the data. The visualization you choose will depend a lot on the data you have and the relationships in your data. This is why it is imperative that you know how to choose the visualization or chart that will best deliver your message. Oftentimes, this means going beyond the default visualization options offered to you by spreadsheet applications. **But how do you choose your visualization?** One of the best teachers is experience\u2014the longer and deeper you are involved in the world of data visualization, the easier it is for you to choose what works best for a specific scenario. But what if you\u0027re a beginner? Well, reading and research goes a long way if you have the time for it. Studying and compiling other successful data visualizations, especially those with similar context and topics to your project, is useful when you are trying to look for inspiration (think mood board). Lastly, if you are pressed for time, you can always consult data visualization catalogs for advise on what visualization to use for each kind of data and relationship you want to show. Most of these are data visualization catalogs are available online and some even give you the step-by-step guide on how to create the visualizations in different applications. ### Tools and techniques The tools and techniques you will use will depend on the presentation or visualization you want to create. Some of these are: **Spreadsheet applications** - [LibreOffice Calc](https://www.libreoffice.org/) - [ONLYOFFICE Spreadsheet](https://www.onlyoffice.com/) - [Google Sheets](http://sheets.google.com) - Microsoft Excel **GIS and mapping applications** - [QGIS](https://qgis.org/) - [Leaflet](https://leafletjs.com/) - [MapLibre](https://maplibre.org) - [Mapbox](https://www.mapbox.com/) **Web-based visualization and design applications** - [Datawrapper](https://www.datawrapper.de/) - [RAWGraphs](https://www.rawgraphs.io/) - [Canva](https://www.canva.com/) - [Google Data Studio](https://datastudio.google.com) **Progamming** - Python - R **Design and image processing applications** - [GIMP](https://www.gimp.org/) - [Inkscape](https://inkscape.org/) - [Krita](https://krita.org/en/) - Abobe Creative Cloud products **Data visualizaton catalogs** - [The Data Visualisation Catalogue](https://datavizcatalogue.com/) - [From Data to Viz](https://www.data-to-viz.com/) - [Data Viz Project](https://datavizproject.com/) - [Chartmaker Directory](https://chartmaker.visualisingdata.com/) - [Python Graph Gallery](https://python-graph-gallery.com/) - [R Graph Gallery](https://www.r-graph-gallery.com/) ```yaml remark type: success text: You can refer to the Making Better Data Presentations part of this website for tips on how to improve your data visualizations. ``` ```yaml remark type: success text: You can refer to the Free and Open Source Tools part of this website for more information about free and open source software and applications that you can use in your data-driven project. ``` ## Common issues ### Failure to identify and segment the audience of the presentation A visualisation is not meant to be a neutral presentation but one that is able to spark discourse, conversation, and ideas in your audience. Communicating different aspects of your results to different audiences will, most of the time, require you to utilize different visualization techniques\u2014a chart that works for one group of people may not work for another. When preparing a data visualization, you must consider not only the data and the elements you want to emphasize but als the context of the presentation and the data visualization literacy of your audience. A [sunburst chart](https://datavizcatalogue.com/methods/sunburst_diagram.html) looks very nice on screen, but is useless for an audience seeing for 30 seconds on a slide from 2 meters of distance. ### Overuse of standard chart types It is very common for a project\u2014especially one without a dedicated data visualization member on the team\u2014to simply use the default chart chosen by their spreadsheet application (e.g. Excel, Google Sheets) to visualize their data. Although a bar chart, line gragh, and pie chart can be read and understood by most people, that does not mean that they are always the best options to convey a message. A very common mistake is using a pie chart with too many categories that some slices end up so small and there is no way to make sense of them visually thus defeating the purpose of using a data visualisation. Read more: https://eagereyes.org/techniques/pie-charts ### Common dataviz mistakes Choosing a chart that does not emphasize the right message is a strategic mistake, but some errors can be more problematic, as they lead your data visualisations to become misleading. ```yaml remark type: success text: You can refer to the Making Better Data Presentations part of this website for tips on how to avoid common data visualization mistakes. ```",
      },
          'pages/better-data-presentations/introduction': {
          'name': 'Making better data presentations',
          'path': 'pages/better-data-presentations/introduction',
          'relpath': 'introduction',
          'text': "# Making better data presentations ## What is this module about? This module focuses on data presentation/visualization and provides tips and things to consider to make your data presentation/visualization better. ## Learning objectives At the end of the module, you should: - Know the basic principles when designing materials for communicating with data - Learn some tips, best practices, and things to avoid when visualizing data",
      },
          'pages/better-data-presentations/design-principles': {
          'name': 'Design Principles',
          'path': 'pages/better-data-presentations/design-principles',
          'relpath': 'design-principles',
          'text': "# Design Principles There are three basic design principles that you must be aware of when communicating visually with data\u2014**simplification, heirarchy, and layout**. ## Simplification - Focus only on the things that matter. - Data can only represent a small part of reality. Don\u0027t try to put too many things in your visualization. - Avoid unnecessary clutter in your charts\u2014but necessary clutter is fine. ## Hierarchy - Some objects are more important than others. Reflect that in your visualizaton. - Utilize **size** - larger elements are more important than smaller elements. - Utilize **contrast** - elements that pop off the page are more important than muted ones. - Utilize **positioning** - our eyes usually follow a common pattern when reading a page, take advantage of that. All things being the same, people who read from left to right usually follow the \u201cZ\u201d path when looking at objects. ## Layouts - Similar to positioning, use your layout to help users know where to look. - Portrait layout is good for documents and posters while a landscape is good for presentations. - **Proximity** - elements placed close to each other will appear to be related. - **Enclosure** - when you enclose things, you encourage the perception of these things belonging together. - **Separation** - adding a line or space between elements makes them seem separated / disjoint. - **Connection** - similar to enclosure, when you connect elements, you encourage the perception of these elements belonging to a group. - Be consistent - establish a style for each design element and use it for similar elements. ```yaml remark type: success text: See Graphic design has rules and they work (Laurel Coons) ```",
      },
          'pages/better-data-presentations/things-to-consider-data-visualization': {
          'name': 'Things to consider',
          'path': 'pages/better-data-presentations/things-to-consider-data-visualization',
          'relpath': 'things-to-consider-data-visualization',
          'text': "# Things to consider ## Start at the beginning - Begin bar charts at zero for a more accurate and truthful comparison of data. - Truncating the Y-axis may lead to misrepresentation of the data that can mislead your audience. ## Avoid distorting charts - Line charts are great at showing trends but are sensitive to changes in the size of the chart. - Stretching the height will tend to overplay (or overestimate) the changes or trend. - Stretching the height will tend to underplay (or underestimate) the changes or trend. ## Use pie charts sparingly - Keep the number of categories to 5 or less. - Don\u0027t use the pie for comparison\u2014e.g. comparing the number of procurements per year - Triple-check that the total value of your pie is exactly 100%. - Don\u0027t make things worse by putting the pie in 3D. - Pie charts are great at showing or highlighting one share of the total. - Bar charts work great as substitutes for pie charts. ## Use colors deliberately - Use color for communication mostly and for decoration sparingly. - Too many colors can confuse or disorient. - Be mindful of your choices of color so you can create inclusive visualizations\u2014e.g. color-blind friendly visulas, etc. - There are online tools that can help you create color palettes and combinations that are inclusive, beautiful, and just work\u2014e.g. [Color Brewer](https://colorbrewer2.org/), [Viz Palette](https://projects.susielu.com/viz-palette) ## Keep right - Align whole numbers flush right to make it easy to find and compare them. - Similarly, you can align decimals usind their decimal point. ## More decimal places is not always better - Extra decimal places imply more precise results but are usually unnecessary and distracting. - Round your numbers off before plotting. ## Convey your message with both form and function - Removing all artistic elements will make your visualization boring. - Having too much artistic elements may distract the audience from the data and the message it conveys. - Add labels and titles. ## Don\u0027t use 3D if your data isn\u0027t 3D - 3D is visually appealing but can make your chart hard to read and understand. - Unless you are plotting something that is actually 3D (e.g. elevation), stick to 2D charts. ## Not everything needs a chart - Why use charts when you can use numbers directly? - Why use charts when you can use bullet points? ```yaml remark type: success text: For more information, you can refer to Data visualization tips by Geckoboard. ```",
      },
          'pages/better-data-presentations/good-infographics': {
          'name': 'Making good infographics',
          'path': 'pages/better-data-presentations/good-infographics',
          'relpath': 'good-infographics',
          'text': "# Making good infographics What makes a good infographic by Daniel Zeevi (DASHBURST) The figure above provides a good overview of what makes a good infographic\u2014it is the combination of **good data, good design, a good story, and shareability**. Although you can still technically make an infographic even if you lack one of the four elements, doing so would lead to your inforgraphic becoming less effective, or worse, dangerous/damaging. ## Data A good inforgraphic requires good data as mentioned in the section about [data trustworthiness, completeness, and quality](../data-pipeline-and-data-driven-projects/verify.html#data-trustworthiness-completeness-and-quality) in the data pipeline\u0027s verify step. As with most processes, making a good infograghic\u2014or any data visualization for that matter\u2014follows the principle of **garbage in, garbage out**. An infographic that lacks good data but has all the other elements is the most dangerous kind. ## Design A good design hooks your audience and catches their attention. This involves choosing the correct design elements\u2014typography, color, layout, imagery\u2014to make your infographic attractive, engaging, and, most importantly, understandable. An infographic that lacks good data but has all the other elements will lack polish and look amateurish. ## Story The design might catch your audience\u0027s attention but it is the story you tell that will keep them reading your infographic. Telling a compelling and interesting story is imperative if you want to effectively communicate your message. An infographic that lacks good story but has all the other elements will be a boring one that\u0027s easily forgotten. ## Shareability Shareability refers to the potential of your inforgraphic to be shared among your target audience and even beyond it\u2014how much reach does your infographic have. This involves decisions such as the format of your infographic, the platforms where it will be posted, and how easily it can be searched online. Shareability is critical in digital spaces and the lack of it would severely decrease the potential of your infographic.",
      },
          'pages/better-data-presentations/exceptions': {
          'name': 'There are always exceptions',
          'path': 'pages/better-data-presentations/exceptions',
          'relpath': 'exceptions',
          'text': "# There are always exceptions ## Ignore all rules \u003e \"If a rule prevents you from improving something, ignore it.\" ([Ignore all rules](https://en.wikipedia.org/wiki/Ignore_all_rules)) ## Break them \u003e \"By all means **break the rules**, and break them **beautifully**, **deliberately** and **well**.\" ([The Elements of Typographic Style](https://en.wikipedia.org/wiki/The_Elements_of_Typographic_Style)) ## But only if you already know what you are doing \u003e \"However, this concept of *breaking the rules* is **only helpful if you already know what you\u2019re doing**. ([What to consider when considering data vis rules](https://lisacharlottemuth.com/datavisrules))",
      },
          'pages/free-and-open-source-tools/introduction': {
          'name': 'Free and open source tools',
          'path': 'pages/free-and-open-source-tools/introduction',
          'relpath': '../free-and-open-source-tools/introduction',
          'text': "# Free and open source tools ## What is this module about? This module will focus primarily in free (as in freedom) and open source tools. Some proprietary but free (as in cost) tools will also be included. You should be familiar with the concept of free and open source software, proprietary software, and freeware. - **Free software** refer to software that abide by the [Four Essential Freedoms of Free Software](https://www.gnu.org/philosophy/free-sw.en.html)\u2014freedom to run, to study, to redistribute, and to distribute copies of your modified versions. This is what we refer to when we say `free (as in freedom)`. That\u0027s not to say that free software is not free in terms of cost. In fact, being easily accessible\u2014i.e. no additional cost to download and install\u2014is a fundamental characteristic of free software. - **Open source software** refer to software that are under an open source license and complies with the [open source definition](https://opensource.org/osd). They are often used synonymously with free software\u2014being open source is a requirement for a software to be free. - **Proprietary software** generally refer to software that restrict what the user can do with the software\u2014this includes restricting access to the source code, requiring a payment or subscription to use the software, preventing users from sharing copies of the software, etc. These software are under a proprietary license. - **Freeware** refer to software that are available for use at no monetary cost. This can include, and usually are, proprietary software. These kinds of freeware cannot be considered to fall under the definition of free software or open source software. This is what we refer to when we say `free (as to cost)`. ```yaml remark type: success text: The opposite of free and open source isn\u0027t commercial, it\u0027s proprietary. ``` ```yaml remark type: success text: Freeware and free software are not the same. ``` ## Learning objectives By the end of this module, you should: - Be aware and familiar of free and open source tools that you can when for working with data",
      },
          'pages/free-and-open-source-tools/data-collection-tools': {
          'name': 'Data collection tools',
          'path': 'pages/free-and-open-source-tools/data-collection-tools',
          'relpath': '../free-and-open-source-tools/data-collection-tools',
          'text': "# Data collection tools ## ODK `open source` `free (as in freedom)` [https://getodk.org/](https://getodk.org/) ODK is a suite of open source tools that help organizations collect and manage data. It consists of: - **ODK Collect** - open source Android app for **data collection** that replaces paper forms used in survey-based data gathering. - **ODK Central** - the **ODK server** that manages user accounts and permissions, stores form definitions, and allows data collection clients like ODK Collect to connect to it for form download and submission upload. - **ODK Build** - a drag-and-drop **form designer**. A common workflow using ODK: - Create survey forms using the XLSForm standard in Excel or Google Sheets. - Upload forms to an ODK Central server. - Download forms into ODK Collect on an Android device. - Use Collect to fill out forms with participants. - Upload survey data from Collect to Central. - Analyze or export data from Central. Learn more about it from the [ODK Documentation](https://docs.getodk.org/). ## ODK-X `open source` `free (as in freedom)` [https://odk-x.org/](https://odk-x.org/) ODK-X is another free and open source toolkit to come out of the Open Data Kit project\u2014the same one that created ODK. Compared to ODK, ODK-X is less mature but it is a more flexible and more complex tool suite. ODK-X allows you to create your own data management applications consisting of survey forms and Javascript-based apps that can render a fully customizable user interface to gather, manage, and visualize data on an Android device. The ODK-X Tool Suite consists of: - **ODK-X Survey**- a customizable **data collection** application. - **ODK-X Tables** - a **data curation and visualization** application that can also run custom-built data collection workflows. - **ODK-X Services** - an application for **user authentication and data synchronization** between the ODK-X applications. - **ODK-X Cloud Endpoints** - a **cloud server** to host data and application files, and to support bi-directional data synchronization across mobile devices. - **ODK-X Suitcase** - a **desktop tool for synchronizing data** with a cloud endpoint. - **ODK-X Application Designer** - a **design environment** for creating, customizing, and previewing your forms, data curation, and visualization applications. This is where you **build your ODK-X applications**. A common data collection workflow using ODK-X: - ODK-X Application Designer for data collection form creation - ODK-X Survey for data collection - ODK-X Services for data sync and database access - ODK-X Cloud Endpoints for data and application files cloud server Learn more about it from the [ODK-X Documentation](https://docs.odk-x.org/). ## KoBoToolbox `open source` `free (as in freedom)` [https://www.kobotoolbox.org/](https://www.kobotoolbox.org/) KoBoToolbox is a suite of free and open source tools for field data collection for use in challenging environments. It allows you to: - **Design forms quickly and easily** using a Form Builder - **Collect data** online and offline via an Android app (KoBoCollect) or on any modern web browser (Enketo). - **Analyze and manage data** through summary reports, graphs, tables, and maps. Aside from deploying your own server, KoBoToolbox has two publicly-available instances that you can use: - Humanitarian Server hosted by UN Office for the Coordination of Humanitarian Affairs (OCHA) - Non-Humanitarian Server hosted by KoboToolbox Learn more about it from the [KoBoToolbox Documentation](https://support.kobotoolbox.org/). ## QField `open source` `free (as in freedom)` `geospatial` [https://qfield.org/](https://qfield.org/) QField is a free and open source application that allows you to bring your QGIS project on the field. It works together with QFieldCloud and QFieldSync so that you can efficiently work on your GIS data outdoors. With QField, you can: - Create a project in QGIS on your desktop. - Collect the data needed for your project on the field. - Sync, edit, and manage the data you collected back into QGIS. Learn more about it from the [QField Documentation](https://docs.qfield.org/). ## Mergin Maps `open source` `free (as in freedom)` `geospatial` [https://merginmaps.com/](https://merginmaps.com/) Mergin Maps allows you to capture geospatial information easily through your mobile or tablet then share it with your team for seamless collaboration. It consists of the QGIS Mergin plugin, Mergin Maps Cloud, and Mergin Maps input. With Mergin Maps, you can: - Setup your GIS project on QGIS - Capture the data you need easily on mobile or tablet using the Mergin Maps Input app for iOS and Android - Store and track changes to your geodata - Integrate the data you collected into QGIS Learn more about it from the [Mergin Maps Documentation](https://merginmaps.com/docs/).",
      },
          'pages/free-and-open-source-tools/data-analysis-and-presentation-tools': {
          'name': 'Data analysis and presentation tools',
          'path': 'pages/free-and-open-source-tools/data-analysis-and-presentation-tools',
          'relpath': '../free-and-open-source-tools/data-analysis-and-presentation-tools',
          'text': "# Data analysis and presentation tools ## LibreOffice Calc `open source` `free (as in freedom)` ### What is it? - LibreOffice Calc is the spreadsheet application of the free and open source office suite LibreOffice. - It is a modern spreadsheet application with features that are as good as, if not better, than those of proprietary alternatives. ### Where do I find it? - [https://www.libreoffice.org/](https://www.libreoffice.org/) ### Do I need to install it? - Yes ### Do I need an account to use it? - No ### Do I need internet to use it? - No ### Do I need to pay to use it? - No ### What kinds of data does it work with? - Tabular data files such as spreadsheets (.ods, .xls, .xlsx) and delimited text files (.csv, .tsv) ### What can I do with it? - Manage spreadsheets and other tabular data files - Perform computations and analyses - Create charts and graphs ### How easy is it to learn and use? - Easy ## Google Sheets `free (as to cost)` ### What is it? - Google Sheets is the spreadsheet application of GSuite. - Cloud-based, free to use, and integrates well with other Google products. ### Where do I find it? - [https://www.libreoffice.org/](https://www.libreoffice.org/) ### Do I need to install it? - No ### Do I need an account to use it? - Yes ### Do I need internet to use it? - Yes ### Do I need to pay to use it? - No ### What kinds of data does it work with? - Tabular data files such as spreadsheets (.ods, .xls, .xlsx) and delimited text files (.csv, .tsv) - Google Sheets spreadheets ### What can I do with it? - Manage spreadsheets and other tabular data files - Perform computations and analyses - Create charts and graphs - Share your data online ### How easy is it to learn and use? - Easy ## Airtable `free (as to cost)` ### What is it? - Airtable combines the ease-of-use of spreadsheets and the power of a database to provide a flexible framework for connecting data and building applications based on your data. ### Where do I find it? - [https://www.airtable.com/](https://www.airtable.com/) ### Do I need to install it? - No ### Do I need an account to use it? - Yes ### Do I need internet to use it? - Yes ### Do I need to pay to use it? - It has free and paid options. ### What kinds of data does it work with? - Different kinds of files stored in tabular format. ### What can I do with it? - Manage tabular data (known as a Base) - Create applications such as forms and websites based on your Base - Perform computations and make visualizations usind your data - Share your data online ### How easy is it to learn and use? - Easy to Moderate depending on what you intend to use it for. ## Datawrapper `open source` `free (as in freedom)` ### What is it? - Datawrapper is an open-source data visualization platform that allows people to create simple, correct, and embeddable charts and maps. ### Where do I find it? - [https://datawrapper.de](https://datawrapper.de) ### Do I need to install it? - No but you can deploy your own instance. ### Do I need an account to use it? - No ### Do I need internet to use it? - Yes but you can deploy your own instance to make it available to you offline. ### Do I need to pay to use it? - It has free and paid options. ### What kinds of data does it work with? - Tabular data such as CSV - URLs to tabular data - Google Sheets spreadsheets ### What can I do with it? - Create interactive and responsive charts (19 types) - Create interactive and responsive maps (choropleth map, symbol map, locator map) - Create interactive and responsive data tables - Share, download, or embed your charts, maps, and tables ### How easy is it to learn and use? - Easy to Moderate depending on what you intend to use it for. ## RAWGraphs `open source` `free (as in freedom)` ### What is it? - RAWGraphs is an open source data visualization framework built with the goal of making the visual representation of complex data easy for everyone. - Almost 30 visual models to visualize quantities, hierarchies, time series and find insights in your data. ### Where do I find it? - [https://www.rawgraphs.io/](https://www.rawgraphs.io/) ### Do I need to install it? - No but you can deploy your own instance. ### Do I need an account to use it? - No ### Do I need internet to use it? - Yes but you can deploy your own instance to make it available to you offline. ### Do I need to pay to use it? - No ### What kinds of data does it work with? - Tabular data such as CSV - URLs to tabular data - SPARQL query results ### What can I do with it? - Create a wide range of charts from your data - Export your chart as a vector or raster image that you can edit in other software ### How easy is it to learn and use? - Easy to Moderate depending on what you intend to use it for. ## QGIS `open source` `free (as in freedom)` ### What is it? - QGIS is a mature, cross-platform, free and open source Geospatial Information System (GIS). - Has features for collecting, storing, analysing, presenting, and managing spatial \u0026 non-spatial data. - Integrates well with other existing geospatial technologies and serves as an integral part of any FOSS4G (Free and Open Source Software for Geospatial) stack. - Runs on GNU/Linux, macOS, Windows, and even Android. ### Where do I find it? - [https://qgis.org](https://qgis.org) ### Do I need to install it? - Yes ### Do I need an account to use it? - No ### Do I need internet to use it? - No ### Do I need to pay to use it? - No ### What kinds of data does it work with? - spatial data (GeoPackage, geoJSON, shapefiles, spatial databases, OGC web services, etc.) - non-spatial data (PDF, non-georefenced images, tabular data, etc.) ### What can I do with it? - Manage, analyze, and visualize data in a spatial way - Create maps - Perform different kinds of spatial analysis such as: - Find the service areas of public utilities - Find the shortest path between points - Find suitable sites for vaccination sites - Determine flood risk ### How easy is it to learn and use? - Easy to Hard depending on what you intend to use it for. ## Leaflet `open source` `free (as in freedom)` ### What is it? - Leaflet is the leading open-source JavaScript library for mobile-friendly interactive maps. ### Where do I find it? - [https://leafletjs.com/](https://leafletjs.com/) ### Do I need an account to use it? - No ### What can I do with it? - Create web/mobile maps and geospatial web/mobile applications. ### How easy is it to learn and use? - Easy to Hard depending on what you intend to use it for. ## MapLibre `open source` `free (as in freedom)` ### What is it? - MapLibre is a community-governed collection of open source mapping libraries. - The initial libraries are forks of the Mapbox GL ecosystem\u2014for the web and mobile platforms\u2014that maintain their open source license. ### Where do I find it? - [https://maplibre.org](https://maplibre.org) ### Do I need an account to use it? - No ### What can I do with it? - Create web/mobile maps and geospatial web/mobile applications. ### How easy is it to learn and use? - Easy to Hard depending on what you intend to use it for. ## Mapbox `free (as to cost)` `source available` ### What is it? - Mapbox is a collection of products that allow you use location information to create applications and solutions. ### Where do I find it? - [https://www.mapbox.com/](https://www.mapbox.com/) ### Do I need an account to use it? - Yes ### Do I need to pay to use it? - It has free and paid options. ### What can I do with it? - Create web/mobile maps and geospatial web/mobile applications. ### How easy is it to learn and use? - Easy to Hard depending on what you intend to use it for. ```yaml remark type: success text: Other popular data visualization and presentation tools include Flourish, Tableau, Google Data Studio, PowerBI, and Canva. These are proprietary. ```",
      },
          'pages/data-ethics/introduction': {
          'name': 'Data ethics',
          'path': 'pages/data-ethics/introduction',
          'relpath': '../data-ethics/introduction',
          'text': "# Data ethics ## What is this module about? This module will provide a general overview of the topic of data ethics. ## Learning objectives At the end of the module, you should be able to: - Define what data ethics means how it relates to your work with data",
      },
          'pages/data-ethics/data-ethics': {
          'name': 'Ethical considerations with data',
          'path': 'pages/data-ethics/data-ethics',
          'relpath': '../data-ethics/data-ethics',
          'text': "# Ethical considerations with data ## What is data ethics \u003e \u201cData ethics is a branch of ethics that evaluates data practices with the potential to adversely impact people and society \u2013 in data collection, sharing and use.\u201d ([The Open Data Institute](https://theodi.org/service/data-ethics/#explainer)) ### Data ethics isn\u2019t just about personal data - Data ethics concerns itself with both personal and non-personal (public) data. - The choice of making public data accessible only through online services, especially in poorer areas, without providing offline alternatives can mean that people without access to the internet are left out and can increase existing inequalities. ### Data ethics isn\u2019t just about compliance with the law - Some data activities can be lawful but not ethical. - Think of the \u201cEmotional Contagion\u201d study by Cornell University and Facebook where they studied the emotions of around 700,000 Facebook users by removing either positive or negative words from their news feeds. - Think of the Cambridge Analytica controversy. ### Data ethics isn\u2019t just about how data is used - Data ethics also applies to how data is collected and shared. - Not collecting data about certain groups of people is bad but collecting data only about certain groups of people is worse as this could create a higher risk of discrimination and profiling. ### Data ethics isn\u2019t about restricting access to data - It can be argued that an ethical approach to data would lead to more openness because people will be more willing to trust entities with their data if they know that the data is collected, shared, and used ethically. - If everyone could trust everyone else that they will be ethical with data then we would see more organizations opening up their datasets instead of restricting access to it. ### Data ethics and data-driven decision-making - Good data ethics practices support data-driven decision-making by addressing people\u2019s fears about how data will be collected, maintained and used When this is the case, people would be more likely to share their data which in turn supports effective decision-making. ## Data bias **Data bias** is an issue in data ethics. This refers to the fact that **human biases are reflected, propagated, and are amplified with data**. Some examples where bias can arise include: - Survey questions are constructed with a particular intent/framing - Selective collection of data from a particular group - Underlying bias in the data sources",
      },
          'pages/common-issues/introduction': {
          'name': 'Common Data Issues',
          'path': 'pages/common-issues/introduction',
          'relpath': '../common-issues/introduction',
          'text': "# Common Data Issues ## What is this module about? This module will provide a general overview of common data issues such as data fallacies. ## Learning objectives At the end of the module, you should be able to: - Know how to identify common data fallacies - Know how to avoid committing common data fallacies",
      },
          'pages/common-issues/data-fallacies': {
          'name': 'Data fallacies',
          'path': 'pages/common-issues/data-fallacies',
          'relpath': '../common-issues/data-fallacies',
          'text': "# Data fallacies \u003e \"Statistics never lie, but lovers often do...\" (J. Tinga, Antonio vs. Reyes, 484 SCRA 353 (2006)) With all due respect to Justice Tinga but **statistics and data do lie** and they do it quite often. ## Cherry picking By selecting or cherry-picking data, the trend of global warming appears to mistakenly stop, as in the period from 1998 to 2012, which is actually a random contrary fluctuation. ### What it is - [Cherry picking](https://en.wikipedia.org/wiki/Cherry_picking) is also known as suppressing evidence or the fallacy of incomplete evidence. - Selecting, using, and presenting only the subset of the data that agree or fit with your claims and beliefs. - This becomes really dangerous when paired with people\u2019s confirmation bias. ### How to avoid it - As a creator, always be faithful to your data and results especially when they do not fully agree with your claims. - As a consumer, ask for the complete dataset or ask yourself: \u201cWhat am I not being told?\u201d ## Data dredging An example of data produced by data dredging through a bot operated by Tyler Vigen, apparently showing a close link between the best word in a spelling bee competition and the number of people in the US killed by venomous spiders. It\u0027s obviously a coincidence: with so many possible comparisons of data of things happening in the world, it is easy to find some unrelated data that shows similar trends. ### What it is - [Data dredging](https://en.wikipedia.org/wiki/Data_dredging) refers to the misuse of data analysis to find patterns in data that can be presented as statistically significant. - Seeking correlation where there is none. Performing countless statistical tests on data and reporting the ones that show correlation. - If you combine enough time with a large enough dataset, you are bound to find things that appear to be correlated. ### How to avoid it - Always be upfront with what you are testing\u2014e.g. using a hypothesis in the analyze step of the data pipeline. - Accept that sometimes things that seem to be correlated aren\u2019t. ## Survivorship bias This hypothetical pattern of damage of returning aircraft shows locations where they can sustain damage and still return home. If the aircraft was reinforced in the most commonly hit areas, this would be a result of survivorship bias because crucial data from fatally damaged planes was being ignored; those hit in other places presumably did not survive. ### What it is - [Survivorship bias](https://en.wikipedia.org/wiki/Survivorship_bias) is the logical error of drawing conclusions from an incomplete dataset composed of data that has survived a selection process and overlooking those that did not, typically because of their lack of visibility. - Example: - Bullet patterns of WW2 aircrafts returning from the war - College dropouts being billionaires\u2014for every 1 dropout who ended up becoming a billionaire, how many thousands more did not? ### How to avoid it - Always try to look at the full picture and ask yourself if you are overlooking anything or if something is missing in your data. - Ask yourself: \"Did your data undergo any selection or trimming process prior to your analysis?\" ## Sampling bias Sampling Bias, via Geckoboard ### What it is - [Sampling bias](https://en.wikipedia.org/wiki/Sampling_bias) occurs when a sample is selected in a way such that some members of the intended population have a lower or higher chance of being included in the sample. - Results in conclusions drawn from a dataset that is not representative of the population you are trying to understand. - Example: - Using an online poll to determine whether students are in favor of online classes. ### How to avoid it - Always try to use a representative sample of your population in your analysis. - Choose an appropriate and robust sampling method. ## Cobra effect The story goes something like this: back in colonial India the top Brit in charge decided there were too many cobras around Delhi. To reduce the population they put in place a cash reward, or bounty, for anyone who brought in a dead cobra. The intention was clear. Legend has it that people did bring in the cobras reliably because some enterprising souls had started breeding cobras for the very purpose of getting the bounty. ### What it is - When an attempted solution to a problem somehow makes it worse as an unintended result of using incorrect stimulation or wrong incentives. - [Other examples](https://en.wikipedia.org/wiki/Perverse_incentive#The_original_cobra_effect). ### How to avoid it - Be careful what you are incentivizing because incentives generally increase the likelihood of what you are incentivizing. ## Gerrymandering / MAUP Different ways to apportion electoral districts leads to different election results ### What it is - In both [gerrymandering and the Modifiable Areal Unit Problem (MAUP)](https://en.wikipedia.org/wiki/Gerrymandering), the outcome of an event (e.g. election, analysis) can vary depending on how you divide the area of interest. ### How to avoid it - Always consider the scale and how you group your data when doing your analysis. Try to see if your results also vary when you vary your scale. ## False causality False Causality, via Geckoboard ### What it is - The belief that because two events occur together or immediately after one another then one must have caused the other. - Correlation does not imply causation. ### How to avoid it - Never assume causation based on correlation alone. ## Danger of summary metrics Four different datasets look identical when examined using simple summary statistics, but vary considerably when graphed. ### What it is - Reliance on summary metrics blur out differences in the dataset. Some datasets may have the same summary metrics (e.g. mean, variance, correlation) but be totally different from each other. - Example: - [Anscombe\u2019s quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) ### How to avoid it - As a provider, show or open the data used for the study instead of just the summary statistics. - As a consumer, always look or ask for the data behind the summary statistics used. ## Other data fallacies - [**Simpson\u0027s paradox**](https://en.wikipedia.org/wiki/Simpson%27s_paradox) - A phenomenon in probability and statistics in which a trend appears in several groups of data but disappears or reverses when the groups are combined. - [**Gambler\u0027s fallacy**](https://rationalwiki.org/wiki/Gambler\u0027s_fallacy) - The erroneous belief that if an event occurs more frequently than normal in the past then it is less likely to occur in the future, when it has already been established that the probability of such events do not depend on what happened in the past. - [**Hawthorne effect**](https://en.wikipedia.org/wiki/Hawthorne_effect) - Also known as the Observer Effect. This is the phenomenon where the actions and behaviors of the subjects of a study change because they are aware that they are being observed/monitored. - [**McNamara fallacy**](https://www.logicallyfallacious.com/logicalfallacies/mcnamara_fallacy.html) - Being too focused on what can easily observed and assuming that does that cannot are irrelevant. This leads to decisions based solely on quantitative observations (i.e., metrics, hard data, statistics) while all qualitative factors are ignored. - [**Publication bias**](https://en.wikipedia.org/wiki/Publication_bias) - Refers to the fallacy that the outcome of a research or experiment influences whether it is published instead of the robustness of the methodology. This results in an imbalance in published papers in favor of positive results when, in reality, more researches using the same methodology but showing negative or inconclusive results may exist. ```yaml remark type: success text: For more information, you can refer to Data fallacies by Geckoboard. ```",
      },
          'pages/common-issues/open-data-misconceptions': {
          'name': 'Open data misconceptions',
          'path': 'pages/common-issues/open-data-misconceptions',
          'relpath': '../common-issues/open-data-misconceptions',
          'text': "# Open data misconceptions ## Beware of openwashing ```yaml remark type: success text: OpenwashingTo spin a product or company as open, although it is not. Derived from \u0027greenwashing.\u0027 (Michelle Thorn)Having an appearance of open-source and open-licensing for marketing purposes, while continuing proprietary practices. (Audrey Watters) ``` Just because an organization or agency says they are open not actually mean that they are. ## The data spectrum Open data doesn\u2019t mean everything is open but respects the rights and privacy of data actors. The openness of data isn\u0027t binary, it\u0027s a spectrum that ranges from closed to shared to public. The Data Spectrum by the ODI. Learn more at: [https://theodi.org/about-the-odi/the-data-spectrum/](https://theodi.org/about-the-odi/the-data-spectrum/)",
      },
          'pages/sharing-opening-data/introduction': {
          'name': 'Sharing and Opening Data',
          'path': 'pages/sharing-opening-data/introduction',
          'relpath': '../sharing-opening-data/introduction',
          'text': "# Sharing and Opening Data ## What is this module about? This module will provide a general overview of topics around sharing and opening data. ## Learning objectives At the end of the module, you should be able to: - Know some of the steps needed to share open data - Learn the concept of five-star open data",
      },
          'pages/sharing-opening-data/open-by-design': {
          'name': 'Open by design',
          'path': 'pages/sharing-opening-data/open-by-design',
          'relpath': '../sharing-opening-data/open-by-design',
          'text': "# Open by design ## Be open by default - **Assumption is open first** then find restrictions (not the other way around). - For example, we assume that government data and data funded by public funds should be open by default. - From this rule, we apply exceptions on what data we need to protect. - Information protected by the Constitution and statutes (e.g. national security, personally-identifiable information) - Ethical considerations of data (e.g. indigenous communities, sensitive information) - It shouldn\u2019t be the other way around where we close all our data at the start and just find which data we can open/share. - Aside from ethical and legal considerations (e.g. constitutionally and statutorily protected data), **public data and data collected by public institutions should be open**. ## Add mechanisms and protections to ensure and facilitate openness - Give [**permission in advance**](../open-data/what-is-open.html#permission-in-advance) - Don\u2019t make it hard to work with your data or tech. Make it **available** and **discoverable**. - Use **open [standards](../open-data/data-standards.html)** and practice interoperability. - **Prefer open source** instead of proprietary and closed solutions. - [**Use an open license**](open-licenses.html). - [**Co-develop and co-create from the start**](co-creation.html). Don\u2019t make it hard for people to collaborate with you ```yaml remark type: success text: You can also refer to How to publish open data - a list of advice and tools from ODI that are helpful in publishing open data. ```",
      },
          'pages/sharing-opening-data/co-creation': {
          'name': 'Co-creation',
          'path': 'pages/sharing-opening-data/co-creation',
          'relpath': '../sharing-opening-data/co-creation',
          'text': "# Co-creation ## People before systems ### Design for people \u003e \u201cIf you design for everyone, you delight no one. That is the recipe for a mediocre product.\u201d (Alan Cooper) ### Engage early and engage often - Identify your key stakeholders and assumptions early. - Persona exercises - Identify the needs and use-cases of your stakeholders. - User stories, Journey mapping - Give your users a say in the design and development process - Co-creation, Design sprints - Validate your assumptions with actual users - Iterate ### Utilize user and people-centered design tools - Persona exercises - User Stories - Journey Mapping - UI Sketching ### Ensure data is used after release - Provide incentive for users to use the data. - Focus on telling compelling stories rather than just the data. - Forge collaborations among the data users and data providers. - Build grassroots communities around open data. ## Co-creation isn\u0027t - Putting different people in one room and expecting them to generate a solution themselves. - Gathering and consolidating ideas from different people. - Finding the \u201cmiddle-ground\u201d solution between stakeholders who have varying, and oftentimes competing, interests. ## Co-creation is - Confronting the inherent power relations and inequalities between your stakeholders. Those who have more must be willing to give-up more and those with the most to lose should have a say in things. - Acknowledging historical injustices and their present-day impacts. - Helping everyone develop a shared point of view no matter how difficult it is.",
      },
          'pages/sharing-opening-data/five-star-open-data': {
          'name': 'Five-star open data',
          'path': 'pages/sharing-opening-data/five-star-open-data',
          'relpath': '../sharing-opening-data/five-star-open-data',
          'text': "# Five-star open data - Suggested by Sir Tim Berners-Lee (inventor of the WWW) as a deployment scheme for open data. - Stars are awarded according to the state of open data from data released under an open license to data linked to other datasets. - Provides a good framework for assessing where you are in terms of opening your data and what steps to take in order to move forward. - [https://5stardata.info/en/](https://5stardata.info/en/) | **Star** | **What it means** | |----------|-----------------------------------------------------------------------------------------------| | \u2606 | Data is available (in whatever format) under an open license | | \u2606\u2606 | Data is available as structured, machine-readable data (e.g. Excel instead of PDFs) | | \u2606\u2606\u2606 | Data is available in a non-proprietary open format (e.g. CSV instead of Excel) | | \u2606\u2606\u2606\u2606 | Uniform Resource Identifier (URI) is used to identify things so others can point to your data | | \u2606\u2606\u2606\u2606\u2606 | Data is linked to other data in order to provide context | ## \u2606 data \u003e Data is available (in whatever format) under an open license ### Costs [-] and benefits [+] **As a consumer...** - [+] You can look, print, and download data. - [+] You can share data with others. - [-] If data is locked-up in a non machine-readable format (pdf, doc, jpeg), it\u2019s hard to get data out of the document. **As a publisher...** - [+] It\u2019s simple to publish. ## \u2606\u2606 data \u003e Data is available as structured, machine-readable data (e.g. Excel instead of PDFs) ### Costs [-] and benefits [+] **As a consumer...** - [+] You can do all you can with \u2606 data. - [+] You can directly process the data or export it to another structured format. - [-] You might need proprietary software to work with data. **As a publisher...** - [+] It\u2019s still simple to publish. ## \u2606\u2606\u2606 data \u003e Data is available in a non-proprietary open format (e.g. CSV instead of Excel) ### Costs [-] and benefits [+] **As a consumer...** - [+] You can do all you can with \u2606\u2606 data. - [+] You can manipulate the data in any way you like without the need for proprietary software. **As a publisher...** - [+] It\u2019s still relatively simple to publish. - [-] You will need to convert your data from proprietary formats to open formats. ## \u2606\u2606\u2606\u2606 data \u003e Uniform Resource Identifier (URI) is used to identify things ### Costs [-] and benefits [+] **As a consumer...** - [+] You can do all you can with \u2606\u2606\u2606 data. - [+] You can link, bookmark, and reuse parts of the data since it is now data in the web. - [-] Understanding the structure of W3C standards such as RDF can be more complicated than tables and spreadsheets. **As a publisher...** - [+] Other publishers can link to your data. - [+] More granular control over your data. - [-] You need to assign URIs to data items and think about how best to represent them. - [-] You need to understand the structure of W3C standards. ## \u2606\u2606\u2606\u2606\u2606 data \u003e Data is linked to other data in order to provide context ### Costs [-] and benefits [+] **As a consumer...** - [+] You can do all you can with \u2606\u2606\u2606\u2606 data. - [+] You can discover other related data easier. - [-] Possibility for broken links. **As a publisher...** - [+] Your data is more discoverable. - [+] The value of your data grows as the network of data attached to it also grows. - [-] You need to invest resources to link your data with other data and prevent link rot.",
      },
          'pages/data-culture/introduction': {
          'name': 'Data culture',
          'path': 'pages/data-culture/introduction',
          'relpath': '../data-culture/introduction',
          'text': "# Data culture ## What is this module about? This module will provide a general overview of topics about how to build data culture and data liceracy at an organizational level. ## Learning objectives At the end of the module, you should be able to: - Define and explain the different facets of data culture and organizational data literacy - Identify steps to build and foster a culture of data",
      },
          'pages/data-culture/building-data-culture': {
          'name': 'Building a culture of data',
          'path': 'pages/data-culture/building-data-culture',
          'relpath': '../data-culture/building-data-culture',
          'text': "# Building a culture of data Having a culture of data means that: - Data is integral and central to your day to day operations and isn\u2019t just an afterthought. - Data is embedded and part of your organization\u0027s identity. **Building data culture and data literacy is hard and does not happen overnight.** It is a long and, often, ardous process. **There are no shortcuts**. There will be a lot of stumbling blocks and learning experiences along the way but both the journey and destination are worth it. Along the way, an organization hoping to build a culture of data and build data literacy must: **1. Use data as evidence.** - Data, when used as evidence, can lead to **better and non-arbitrary** policies and decisions. - Evidence-based decision-making requires: - a sound theory - a coherent set of testable hypotheses - a robust dataset to validate and refine the hypotheses **2. [Use data ethically.](../data-ethics/data-ethics.html)** **3. [Knows its data.](knowing-your-data.html)** **4. [Knows its users.](knowing-your-users.html)** **5. [Empowers members to learn, improve, and share their data skills.](data-socialization.html)**",
      },
          'pages/data-culture/knowing-your-data': {
          'name': 'Knowing your data',
          'path': 'pages/data-culture/knowing-your-data',
          'relpath': '../data-culture/knowing-your-data',
          'text': "# Knowing your data ## The state of your data (data and skills inventory) ### What data do you currently have? - Where are they located? - How are they accessed? - Who can access them? - In what formats are they in? - Are they open? ### What other data do you need? - Where can you find them? - How do you get them? - Why do you need them? - In what formats are they in? - Are they open? ### ### What skills do you currently have? - What skills do you want to share? ### What skills do you want to learn? - Are there people in the organizaton who can help you learn these skills?",
      },
          'pages/data-culture/knowing-your-users': {
          'name': 'Knowing your users',
          'path': 'pages/data-culture/knowing-your-users',
          'relpath': '../data-culture/knowing-your-users',
          'text': "# Knowing your users ## There isn\u2019t a single type of data user - We should **move away from the data user stereotypes**. Data users aren\u0027t limited to IT people, \u201cnerds\u201d, or those with no social skills. - The field of data is **diverse and inclusive**. - Data users come in **different shapes, sizes, and skills**. - Different data users also have **different needs**. - One important step in building data culture is understanding what type of data users you have.",
      },
          'pages/data-culture/data-socialization': {
          'name': 'Data socialization',
          'path': 'pages/data-culture/data-socialization',
          'relpath': '../data-culture/data-socialization',
          'text': "# Data socialization Data Socialization is the combination of **sharing and widening data skills** from the basics to intermediary, while **fostering a data culture**. ## How do we start socializing? ### Skills Scoping - Getting a baseline understanding of the skills and opportunities for an organization -- make people talk about data, what skills they want to learn or share, etc. ### Informal Data Working Group - Can also be called Meetups. Open to everyone where people are free to share and learn new data skills (initially based on the outcomes of the Skills Scoping). ### People Before Data Create spaces for conversations and giving everyone equal access to explore their data skills. ### Track people\u0027s progress and iterate Building data literacy and learning data skills take time. It is an investment on the part of the individual and the organization and involves checking both individual and organizational progress, evaluating the success of interventions, and adapting to the results accordingly. ```yaml remark type: success text: For Data Culture to be sustainable, it needs to be inclusive, uncomfortably inclusive, with a focus on building organizational confidence and trust. ```",
      },
          'pages/other-resources': {
          'name': 'Other resources',
          'path': 'pages/other-resources',
          'relpath': '../other-resources',
          'text': "# Other resources",
      },
      };
  const searchIndex = lunr(function () {
    this.ref("path")
    this.field("name", { boost: 10 })
    this.field("text")
    for (const item of Object.values(searchItems)) {
      this.add(item)
    }
  });
  const searchOutput = document.getElementById('livemark-search-output')
  const searchInput = document.getElementById('livemark-search-input')
  searchInput.addEventListener('input', search)
  prepare()
  search()
});

</script>

<div id="livemark-search">
  <div id="livemark-search-output"></div>
  <input id="livemark-search-input" type="search" placeholder="Search...">
</div>
</body>
</html>