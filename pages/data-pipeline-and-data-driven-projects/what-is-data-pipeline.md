# What is the Data Pipeline?

The [Data Pipeline](https://schoolofdata.org/methodology/) is an approach developed by the School of Data network to work with data from beginning to end. Aside from being a flexible guide for doing data-driven projects, it is also a wonderful tool for teaching how to work with data to beginners and experienced data practitioners alike as it divides the process into understandable and manageable steps. It is simple enough for beginners to grasp yet open enough for experienced practitioners to play around with.

The Data Pipeline is an ever-improving, dynamic tool that has been utilized, extended, and improved upon by countless data practioners over the years. Its current steps are:
- **Define**
- **Find**
- **Get**
- **Verify**
- **Clean**
- **Analyze**
- **Present**

```yaml remark
type: success
text: Although the Pipeline is a template, it should not be thought of as a rigid one. It is <strong>designed to be easily adaptable</strong> to different contexts and you shouldn't be afraid to experiment with it. 
```

```yaml remark
type: success
text: It is also important to note that the process of using the <strong>Data Pipeline is not always linear</strong>â€”you may need to do the find and get steps multiple times or repeat the verify and clean steps if you find mistakes in the outcome of your analysis.
```

<figure>
<img src="" width="180">
<figcaption><i><br>The Data Pipeline (2022)</i></a></figcaption>
</figure>